bert-output/embeddings/LayerNorm/beta	[768]
bert-output/embeddings/LayerNorm/beta/adam_m	[768]
bert-output/embeddings/LayerNorm/beta/adam_v	[768]
bert-output/embeddings/LayerNorm/gamma	[768]
bert-output/embeddings/LayerNorm/gamma/adam_m	[768]
bert-output/embeddings/LayerNorm/gamma/adam_v	[768]
bert-output/embeddings/position_embeddings	[512, 768]
bert-output/embeddings/position_embeddings/adam_m	[512, 768]
bert-output/embeddings/position_embeddings/adam_v	[512, 768]
bert-output/embeddings/token_type_embeddings	[2, 768]
bert-output/embeddings/token_type_embeddings/adam_m	[2, 768]
bert-output/embeddings/token_type_embeddings/adam_v	[2, 768]
bert-output/embeddings/word_embeddings	[30522, 768]
bert-output/embeddings/word_embeddings/adam_m	[30522, 768]
bert-output/embeddings/word_embeddings/adam_v	[30522, 768]
bert/embeddings/LayerNorm/beta	[768]
bert/embeddings/LayerNorm/beta/adam_m	[768]
bert/embeddings/LayerNorm/beta/adam_v	[768]
bert/embeddings/LayerNorm/gamma	[768]
bert/embeddings/LayerNorm/gamma/adam_m	[768]
bert/embeddings/LayerNorm/gamma/adam_v	[768]
bert/embeddings/position_embeddings	[512, 768]
bert/embeddings/position_embeddings/adam_m	[512, 768]
bert/embeddings/position_embeddings/adam_v	[512, 768]
bert/embeddings/token_type_embeddings	[2, 768]
bert/embeddings/token_type_embeddings/adam_m	[2, 768]
bert/embeddings/token_type_embeddings/adam_v	[2, 768]
bert/embeddings/word_embeddings	[30522, 768]
bert/embeddings/word_embeddings/adam_m	[30522, 768]
bert/embeddings/word_embeddings/adam_v	[30522, 768]
bert/encoder/layer_0/attention/output/LayerNorm/beta	[768]
bert/encoder/layer_0/attention/output/LayerNorm/beta/adam_m	[768]
bert/encoder/layer_0/attention/output/LayerNorm/beta/adam_v	[768]
bert/encoder/layer_0/attention/output/LayerNorm/gamma	[768]
bert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_m	[768]
bert/encoder/layer_0/attention/output/LayerNorm/gamma/adam_v	[768]
bert/encoder/layer_0/attention/output/dense/bias	[768]
bert/encoder/layer_0/attention/output/dense/bias/adam_m	[768]
bert/encoder/layer_0/attention/output/dense/bias/adam_v	[768]
bert/encoder/layer_0/attention/output/dense/kernel	[768, 768]
bert/encoder/layer_0/attention/output/dense/kernel/adam_m	[768, 768]
bert/encoder/layer_0/attention/output/dense/kernel/adam_v	[768, 768]
bert/encoder/layer_0/attention/self/key/bias	[768]
bert/encoder/layer_0/attention/self/key/bias/adam_m	[768]
bert/encoder/layer_0/attention/self/key/bias/adam_v	[768]
bert/encoder/layer_0/attention/self/key/kernel	[768, 768]
bert/encoder/layer_0/attention/self/key/kernel/adam_m	[768, 768]
bert/encoder/layer_0/attention/self/key/kernel/adam_v	[768, 768]
bert/encoder/layer_0/attention/self/query/bias	[768]
bert/encoder/layer_0/attention/self/query/bias/adam_m	[768]
bert/encoder/layer_0/attention/self/query/bias/adam_v	[768]
bert/encoder/layer_0/attention/self/query/kernel	[768, 768]
bert/encoder/layer_0/attention/self/query/kernel/adam_m	[768, 768]
bert/encoder/layer_0/attention/self/query/kernel/adam_v	[768, 768]
bert/encoder/layer_0/attention/self/value/bias	[768]
bert/encoder/layer_0/attention/self/value/bias/adam_m	[768]
bert/encoder/layer_0/attention/self/value/bias/adam_v	[768]
bert/encoder/layer_0/attention/self/value/kernel	[768, 768]
bert/encoder/layer_0/attention/self/value/kernel/adam_m	[768, 768]
bert/encoder/layer_0/attention/self/value/kernel/adam_v	[768, 768]
bert/encoder/layer_0/intermediate/dense/bias	[3072]
bert/encoder/layer_0/intermediate/dense/bias/adam_m	[3072]
bert/encoder/layer_0/intermediate/dense/bias/adam_v	[3072]
bert/encoder/layer_0/intermediate/dense/kernel	[768, 3072]
bert/encoder/layer_0/intermediate/dense/kernel/adam_m	[768, 3072]
bert/encoder/layer_0/intermediate/dense/kernel/adam_v	[768, 3072]
bert/encoder/layer_0/output/LayerNorm/beta	[768]
bert/encoder/layer_0/output/LayerNorm/beta/adam_m	[768]
bert/encoder/layer_0/output/LayerNorm/beta/adam_v	[768]
bert/encoder/layer_0/output/LayerNorm/gamma	[768]
bert/encoder/layer_0/output/LayerNorm/gamma/adam_m	[768]
bert/encoder/layer_0/output/LayerNorm/gamma/adam_v	[768]
bert/encoder/layer_0/output/dense/bias	[768]
bert/encoder/layer_0/output/dense/bias/adam_m	[768]
bert/encoder/layer_0/output/dense/bias/adam_v	[768]
bert/encoder/layer_0/output/dense/kernel	[3072, 768]
bert/encoder/layer_0/output/dense/kernel/adam_m	[3072, 768]
bert/encoder/layer_0/output/dense/kernel/adam_v	[3072, 768]
bert/encoder/layer_1/attention/output/LayerNorm/beta	[768]
bert/encoder/layer_1/attention/output/LayerNorm/beta/adam_m	[768]
bert/encoder/layer_1/attention/output/LayerNorm/beta/adam_v	[768]
bert/encoder/layer_1/attention/output/LayerNorm/gamma	[768]
bert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_m	[768]
bert/encoder/layer_1/attention/output/LayerNorm/gamma/adam_v	[768]
bert/encoder/layer_1/attention/output/dense/bias	[768]
bert/encoder/layer_1/attention/output/dense/bias/adam_m	[768]
bert/encoder/layer_1/attention/output/dense/bias/adam_v	[768]
bert/encoder/layer_1/attention/output/dense/kernel	[768, 768]
bert/encoder/layer_1/attention/output/dense/kernel/adam_m	[768, 768]
bert/encoder/layer_1/attention/output/dense/kernel/adam_v	[768, 768]
bert/encoder/layer_1/attention/self/key/bias	[768]
bert/encoder/layer_1/attention/self/key/bias/adam_m	[768]
bert/encoder/layer_1/attention/self/key/bias/adam_v	[768]
bert/encoder/layer_1/attention/self/key/kernel	[768, 768]
bert/encoder/layer_1/attention/self/key/kernel/adam_m	[768, 768]
bert/encoder/layer_1/attention/self/key/kernel/adam_v	[768, 768]
bert/encoder/layer_1/attention/self/query/bias	[768]
bert/encoder/layer_1/attention/self/query/bias/adam_m	[768]
bert/encoder/layer_1/attention/self/query/bias/adam_v	[768]
bert/encoder/layer_1/attention/self/query/kernel	[768, 768]
bert/encoder/layer_1/attention/self/query/kernel/adam_m	[768, 768]
bert/encoder/layer_1/attention/self/query/kernel/adam_v	[768, 768]
bert/encoder/layer_1/attention/self/value/bias	[768]
bert/encoder/layer_1/attention/self/value/bias/adam_m	[768]
bert/encoder/layer_1/attention/self/value/bias/adam_v	[768]
bert/encoder/layer_1/attention/self/value/kernel	[768, 768]
bert/encoder/layer_1/attention/self/value/kernel/adam_m	[768, 768]
bert/encoder/layer_1/attention/self/value/kernel/adam_v	[768, 768]
bert/encoder/layer_1/intermediate/dense/bias	[3072]
bert/encoder/layer_1/intermediate/dense/bias/adam_m	[3072]
bert/encoder/layer_1/intermediate/dense/bias/adam_v	[3072]
bert/encoder/layer_1/intermediate/dense/kernel	[768, 3072]
bert/encoder/layer_1/intermediate/dense/kernel/adam_m	[768, 3072]
bert/encoder/layer_1/intermediate/dense/kernel/adam_v	[768, 3072]
bert/encoder/layer_1/output/LayerNorm/beta	[768]
bert/encoder/layer_1/output/LayerNorm/beta/adam_m	[768]
bert/encoder/layer_1/output/LayerNorm/beta/adam_v	[768]
bert/encoder/layer_1/output/LayerNorm/gamma	[768]
bert/encoder/layer_1/output/LayerNorm/gamma/adam_m	[768]
bert/encoder/layer_1/output/LayerNorm/gamma/adam_v	[768]
bert/encoder/layer_1/output/dense/bias	[768]
bert/encoder/layer_1/output/dense/bias/adam_m	[768]
bert/encoder/layer_1/output/dense/bias/adam_v	[768]
bert/encoder/layer_1/output/dense/kernel	[3072, 768]
bert/encoder/layer_1/output/dense/kernel/adam_m	[3072, 768]
bert/encoder/layer_1/output/dense/kernel/adam_v	[3072, 768]
bert/encoder/layer_10/attention/output/LayerNorm/beta	[768]
bert/encoder/layer_10/attention/output/LayerNorm/beta/adam_m	[768]
bert/encoder/layer_10/attention/output/LayerNorm/beta/adam_v	[768]
bert/encoder/layer_10/attention/output/LayerNorm/gamma	[768]
bert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_m	[768]
bert/encoder/layer_10/attention/output/LayerNorm/gamma/adam_v	[768]
bert/encoder/layer_10/attention/output/dense/bias	[768]
bert/encoder/layer_10/attention/output/dense/bias/adam_m	[768]
bert/encoder/layer_10/attention/output/dense/bias/adam_v	[768]
bert/encoder/layer_10/attention/output/dense/kernel	[768, 768]
bert/encoder/layer_10/attention/output/dense/kernel/adam_m	[768, 768]
bert/encoder/layer_10/attention/output/dense/kernel/adam_v	[768, 768]
bert/encoder/layer_10/attention/self/key/bias	[768]
bert/encoder/layer_10/attention/self/key/bias/adam_m	[768]
bert/encoder/layer_10/attention/self/key/bias/adam_v	[768]
bert/encoder/layer_10/attention/self/key/kernel	[768, 768]
bert/encoder/layer_10/attention/self/key/kernel/adam_m	[768, 768]
bert/encoder/layer_10/attention/self/key/kernel/adam_v	[768, 768]
bert/encoder/layer_10/attention/self/query/bias	[768]
bert/encoder/layer_10/attention/self/query/bias/adam_m	[768]
bert/encoder/layer_10/attention/self/query/bias/adam_v	[768]
bert/encoder/layer_10/attention/self/query/kernel	[768, 768]
bert/encoder/layer_10/attention/self/query/kernel/adam_m	[768, 768]
bert/encoder/layer_10/attention/self/query/kernel/adam_v	[768, 768]
bert/encoder/layer_10/attention/self/value/bias	[768]
bert/encoder/layer_10/attention/self/value/bias/adam_m	[768]
bert/encoder/layer_10/attention/self/value/bias/adam_v	[768]
bert/encoder/layer_10/attention/self/value/kernel	[768, 768]
bert/encoder/layer_10/attention/self/value/kernel/adam_m	[768, 768]
bert/encoder/layer_10/attention/self/value/kernel/adam_v	[768, 768]
bert/encoder/layer_10/intermediate/dense/bias	[3072]
bert/encoder/layer_10/intermediate/dense/bias/adam_m	[3072]
bert/encoder/layer_10/intermediate/dense/bias/adam_v	[3072]
bert/encoder/layer_10/intermediate/dense/kernel	[768, 3072]
bert/encoder/layer_10/intermediate/dense/kernel/adam_m	[768, 3072]
bert/encoder/layer_10/intermediate/dense/kernel/adam_v	[768, 3072]
bert/encoder/layer_10/output/LayerNorm/beta	[768]
bert/encoder/layer_10/output/LayerNorm/beta/adam_m	[768]
bert/encoder/layer_10/output/LayerNorm/beta/adam_v	[768]
bert/encoder/layer_10/output/LayerNorm/gamma	[768]
bert/encoder/layer_10/output/LayerNorm/gamma/adam_m	[768]
bert/encoder/layer_10/output/LayerNorm/gamma/adam_v	[768]
bert/encoder/layer_10/output/dense/bias	[768]
bert/encoder/layer_10/output/dense/bias/adam_m	[768]
bert/encoder/layer_10/output/dense/bias/adam_v	[768]
bert/encoder/layer_10/output/dense/kernel	[3072, 768]
bert/encoder/layer_10/output/dense/kernel/adam_m	[3072, 768]
bert/encoder/layer_10/output/dense/kernel/adam_v	[3072, 768]
bert/encoder/layer_11/attention/output/LayerNorm/beta	[768]
bert/encoder/layer_11/attention/output/LayerNorm/beta/adam_m	[768]
bert/encoder/layer_11/attention/output/LayerNorm/beta/adam_v	[768]
bert/encoder/layer_11/attention/output/LayerNorm/gamma	[768]
bert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_m	[768]
bert/encoder/layer_11/attention/output/LayerNorm/gamma/adam_v	[768]
bert/encoder/layer_11/attention/output/dense/bias	[768]
bert/encoder/layer_11/attention/output/dense/bias/adam_m	[768]
bert/encoder/layer_11/attention/output/dense/bias/adam_v	[768]
bert/encoder/layer_11/attention/output/dense/kernel	[768, 768]
bert/encoder/layer_11/attention/output/dense/kernel/adam_m	[768, 768]
bert/encoder/layer_11/attention/output/dense/kernel/adam_v	[768, 768]
bert/encoder/layer_11/attention/self/key/bias	[768]
bert/encoder/layer_11/attention/self/key/bias/adam_m	[768]
bert/encoder/layer_11/attention/self/key/bias/adam_v	[768]
bert/encoder/layer_11/attention/self/key/kernel	[768, 768]
bert/encoder/layer_11/attention/self/key/kernel/adam_m	[768, 768]
bert/encoder/layer_11/attention/self/key/kernel/adam_v	[768, 768]
bert/encoder/layer_11/attention/self/query/bias	[768]
bert/encoder/layer_11/attention/self/query/bias/adam_m	[768]
bert/encoder/layer_11/attention/self/query/bias/adam_v	[768]
bert/encoder/layer_11/attention/self/query/kernel	[768, 768]
bert/encoder/layer_11/attention/self/query/kernel/adam_m	[768, 768]
bert/encoder/layer_11/attention/self/query/kernel/adam_v	[768, 768]
bert/encoder/layer_11/attention/self/value/bias	[768]
bert/encoder/layer_11/attention/self/value/bias/adam_m	[768]
bert/encoder/layer_11/attention/self/value/bias/adam_v	[768]
bert/encoder/layer_11/attention/self/value/kernel	[768, 768]
bert/encoder/layer_11/attention/self/value/kernel/adam_m	[768, 768]
bert/encoder/layer_11/attention/self/value/kernel/adam_v	[768, 768]
bert/encoder/layer_11/intermediate/dense/bias	[3072]
bert/encoder/layer_11/intermediate/dense/bias/adam_m	[3072]
bert/encoder/layer_11/intermediate/dense/bias/adam_v	[3072]
bert/encoder/layer_11/intermediate/dense/kernel	[768, 3072]
bert/encoder/layer_11/intermediate/dense/kernel/adam_m	[768, 3072]
bert/encoder/layer_11/intermediate/dense/kernel/adam_v	[768, 3072]
bert/encoder/layer_11/output/LayerNorm/beta	[768]
bert/encoder/layer_11/output/LayerNorm/beta/adam_m	[768]
bert/encoder/layer_11/output/LayerNorm/beta/adam_v	[768]
bert/encoder/layer_11/output/LayerNorm/gamma	[768]
bert/encoder/layer_11/output/LayerNorm/gamma/adam_m	[768]
bert/encoder/layer_11/output/LayerNorm/gamma/adam_v	[768]
bert/encoder/layer_11/output/dense/bias	[768]
bert/encoder/layer_11/output/dense/bias/adam_m	[768]
bert/encoder/layer_11/output/dense/bias/adam_v	[768]
bert/encoder/layer_11/output/dense/kernel	[3072, 768]
bert/encoder/layer_11/output/dense/kernel/adam_m	[3072, 768]
bert/encoder/layer_11/output/dense/kernel/adam_v	[3072, 768]
bert/encoder/layer_2/attention/output/LayerNorm/beta	[768]
bert/encoder/layer_2/attention/output/LayerNorm/beta/adam_m	[768]
bert/encoder/layer_2/attention/output/LayerNorm/beta/adam_v	[768]
bert/encoder/layer_2/attention/output/LayerNorm/gamma	[768]
bert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_m	[768]
bert/encoder/layer_2/attention/output/LayerNorm/gamma/adam_v	[768]
bert/encoder/layer_2/attention/output/dense/bias	[768]
bert/encoder/layer_2/attention/output/dense/bias/adam_m	[768]
bert/encoder/layer_2/attention/output/dense/bias/adam_v	[768]
bert/encoder/layer_2/attention/output/dense/kernel	[768, 768]
bert/encoder/layer_2/attention/output/dense/kernel/adam_m	[768, 768]
bert/encoder/layer_2/attention/output/dense/kernel/adam_v	[768, 768]
bert/encoder/layer_2/attention/self/key/bias	[768]
bert/encoder/layer_2/attention/self/key/bias/adam_m	[768]
bert/encoder/layer_2/attention/self/key/bias/adam_v	[768]
bert/encoder/layer_2/attention/self/key/kernel	[768, 768]
bert/encoder/layer_2/attention/self/key/kernel/adam_m	[768, 768]
bert/encoder/layer_2/attention/self/key/kernel/adam_v	[768, 768]
bert/encoder/layer_2/attention/self/query/bias	[768]
bert/encoder/layer_2/attention/self/query/bias/adam_m	[768]
bert/encoder/layer_2/attention/self/query/bias/adam_v	[768]
bert/encoder/layer_2/attention/self/query/kernel	[768, 768]
bert/encoder/layer_2/attention/self/query/kernel/adam_m	[768, 768]
bert/encoder/layer_2/attention/self/query/kernel/adam_v	[768, 768]
bert/encoder/layer_2/attention/self/value/bias	[768]
bert/encoder/layer_2/attention/self/value/bias/adam_m	[768]
bert/encoder/layer_2/attention/self/value/bias/adam_v	[768]
bert/encoder/layer_2/attention/self/value/kernel	[768, 768]
bert/encoder/layer_2/attention/self/value/kernel/adam_m	[768, 768]
bert/encoder/layer_2/attention/self/value/kernel/adam_v	[768, 768]
bert/encoder/layer_2/intermediate/dense/bias	[3072]
bert/encoder/layer_2/intermediate/dense/bias/adam_m	[3072]
bert/encoder/layer_2/intermediate/dense/bias/adam_v	[3072]
bert/encoder/layer_2/intermediate/dense/kernel	[768, 3072]
bert/encoder/layer_2/intermediate/dense/kernel/adam_m	[768, 3072]
bert/encoder/layer_2/intermediate/dense/kernel/adam_v	[768, 3072]
bert/encoder/layer_2/output/LayerNorm/beta	[768]
bert/encoder/layer_2/output/LayerNorm/beta/adam_m	[768]
bert/encoder/layer_2/output/LayerNorm/beta/adam_v	[768]
bert/encoder/layer_2/output/LayerNorm/gamma	[768]
bert/encoder/layer_2/output/LayerNorm/gamma/adam_m	[768]
bert/encoder/layer_2/output/LayerNorm/gamma/adam_v	[768]
bert/encoder/layer_2/output/dense/bias	[768]
bert/encoder/layer_2/output/dense/bias/adam_m	[768]
bert/encoder/layer_2/output/dense/bias/adam_v	[768]
bert/encoder/layer_2/output/dense/kernel	[3072, 768]
bert/encoder/layer_2/output/dense/kernel/adam_m	[3072, 768]
bert/encoder/layer_2/output/dense/kernel/adam_v	[3072, 768]
bert/encoder/layer_3/attention/output/LayerNorm/beta	[768]
bert/encoder/layer_3/attention/output/LayerNorm/beta/adam_m	[768]
bert/encoder/layer_3/attention/output/LayerNorm/beta/adam_v	[768]
bert/encoder/layer_3/attention/output/LayerNorm/gamma	[768]
bert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_m	[768]
bert/encoder/layer_3/attention/output/LayerNorm/gamma/adam_v	[768]
bert/encoder/layer_3/attention/output/dense/bias	[768]
bert/encoder/layer_3/attention/output/dense/bias/adam_m	[768]
bert/encoder/layer_3/attention/output/dense/bias/adam_v	[768]
bert/encoder/layer_3/attention/output/dense/kernel	[768, 768]
bert/encoder/layer_3/attention/output/dense/kernel/adam_m	[768, 768]
bert/encoder/layer_3/attention/output/dense/kernel/adam_v	[768, 768]
bert/encoder/layer_3/attention/self/key/bias	[768]
bert/encoder/layer_3/attention/self/key/bias/adam_m	[768]
bert/encoder/layer_3/attention/self/key/bias/adam_v	[768]
bert/encoder/layer_3/attention/self/key/kernel	[768, 768]
bert/encoder/layer_3/attention/self/key/kernel/adam_m	[768, 768]
bert/encoder/layer_3/attention/self/key/kernel/adam_v	[768, 768]
bert/encoder/layer_3/attention/self/query/bias	[768]
bert/encoder/layer_3/attention/self/query/bias/adam_m	[768]
bert/encoder/layer_3/attention/self/query/bias/adam_v	[768]
bert/encoder/layer_3/attention/self/query/kernel	[768, 768]
bert/encoder/layer_3/attention/self/query/kernel/adam_m	[768, 768]
bert/encoder/layer_3/attention/self/query/kernel/adam_v	[768, 768]
bert/encoder/layer_3/attention/self/value/bias	[768]
bert/encoder/layer_3/attention/self/value/bias/adam_m	[768]
bert/encoder/layer_3/attention/self/value/bias/adam_v	[768]
bert/encoder/layer_3/attention/self/value/kernel	[768, 768]
bert/encoder/layer_3/attention/self/value/kernel/adam_m	[768, 768]
bert/encoder/layer_3/attention/self/value/kernel/adam_v	[768, 768]
bert/encoder/layer_3/intermediate/dense/bias	[3072]
bert/encoder/layer_3/intermediate/dense/bias/adam_m	[3072]
bert/encoder/layer_3/intermediate/dense/bias/adam_v	[3072]
bert/encoder/layer_3/intermediate/dense/kernel	[768, 3072]
bert/encoder/layer_3/intermediate/dense/kernel/adam_m	[768, 3072]
bert/encoder/layer_3/intermediate/dense/kernel/adam_v	[768, 3072]
bert/encoder/layer_3/output/LayerNorm/beta	[768]
bert/encoder/layer_3/output/LayerNorm/beta/adam_m	[768]
bert/encoder/layer_3/output/LayerNorm/beta/adam_v	[768]
bert/encoder/layer_3/output/LayerNorm/gamma	[768]
bert/encoder/layer_3/output/LayerNorm/gamma/adam_m	[768]
bert/encoder/layer_3/output/LayerNorm/gamma/adam_v	[768]
bert/encoder/layer_3/output/dense/bias	[768]
bert/encoder/layer_3/output/dense/bias/adam_m	[768]
bert/encoder/layer_3/output/dense/bias/adam_v	[768]
bert/encoder/layer_3/output/dense/kernel	[3072, 768]
bert/encoder/layer_3/output/dense/kernel/adam_m	[3072, 768]
bert/encoder/layer_3/output/dense/kernel/adam_v	[3072, 768]
bert/encoder/layer_4/attention/output/LayerNorm/beta	[768]
bert/encoder/layer_4/attention/output/LayerNorm/beta/adam_m	[768]
bert/encoder/layer_4/attention/output/LayerNorm/beta/adam_v	[768]
bert/encoder/layer_4/attention/output/LayerNorm/gamma	[768]
bert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_m	[768]
bert/encoder/layer_4/attention/output/LayerNorm/gamma/adam_v	[768]
bert/encoder/layer_4/attention/output/dense/bias	[768]
bert/encoder/layer_4/attention/output/dense/bias/adam_m	[768]
bert/encoder/layer_4/attention/output/dense/bias/adam_v	[768]
bert/encoder/layer_4/attention/output/dense/kernel	[768, 768]
bert/encoder/layer_4/attention/output/dense/kernel/adam_m	[768, 768]
bert/encoder/layer_4/attention/output/dense/kernel/adam_v	[768, 768]
bert/encoder/layer_4/attention/self/key/bias	[768]
bert/encoder/layer_4/attention/self/key/bias/adam_m	[768]
bert/encoder/layer_4/attention/self/key/bias/adam_v	[768]
bert/encoder/layer_4/attention/self/key/kernel	[768, 768]
bert/encoder/layer_4/attention/self/key/kernel/adam_m	[768, 768]
bert/encoder/layer_4/attention/self/key/kernel/adam_v	[768, 768]
bert/encoder/layer_4/attention/self/query/bias	[768]
bert/encoder/layer_4/attention/self/query/bias/adam_m	[768]
bert/encoder/layer_4/attention/self/query/bias/adam_v	[768]
bert/encoder/layer_4/attention/self/query/kernel	[768, 768]
bert/encoder/layer_4/attention/self/query/kernel/adam_m	[768, 768]
bert/encoder/layer_4/attention/self/query/kernel/adam_v	[768, 768]
bert/encoder/layer_4/attention/self/value/bias	[768]
bert/encoder/layer_4/attention/self/value/bias/adam_m	[768]
bert/encoder/layer_4/attention/self/value/bias/adam_v	[768]
bert/encoder/layer_4/attention/self/value/kernel	[768, 768]
bert/encoder/layer_4/attention/self/value/kernel/adam_m	[768, 768]
bert/encoder/layer_4/attention/self/value/kernel/adam_v	[768, 768]
bert/encoder/layer_4/intermediate/dense/bias	[3072]
bert/encoder/layer_4/intermediate/dense/bias/adam_m	[3072]
bert/encoder/layer_4/intermediate/dense/bias/adam_v	[3072]
bert/encoder/layer_4/intermediate/dense/kernel	[768, 3072]
bert/encoder/layer_4/intermediate/dense/kernel/adam_m	[768, 3072]
bert/encoder/layer_4/intermediate/dense/kernel/adam_v	[768, 3072]
bert/encoder/layer_4/output/LayerNorm/beta	[768]
bert/encoder/layer_4/output/LayerNorm/beta/adam_m	[768]
bert/encoder/layer_4/output/LayerNorm/beta/adam_v	[768]
bert/encoder/layer_4/output/LayerNorm/gamma	[768]
bert/encoder/layer_4/output/LayerNorm/gamma/adam_m	[768]
bert/encoder/layer_4/output/LayerNorm/gamma/adam_v	[768]
bert/encoder/layer_4/output/dense/bias	[768]
bert/encoder/layer_4/output/dense/bias/adam_m	[768]
bert/encoder/layer_4/output/dense/bias/adam_v	[768]
bert/encoder/layer_4/output/dense/kernel	[3072, 768]
bert/encoder/layer_4/output/dense/kernel/adam_m	[3072, 768]
bert/encoder/layer_4/output/dense/kernel/adam_v	[3072, 768]
bert/encoder/layer_5/attention/output/LayerNorm/beta	[768]
bert/encoder/layer_5/attention/output/LayerNorm/beta/adam_m	[768]
bert/encoder/layer_5/attention/output/LayerNorm/beta/adam_v	[768]
bert/encoder/layer_5/attention/output/LayerNorm/gamma	[768]
bert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_m	[768]
bert/encoder/layer_5/attention/output/LayerNorm/gamma/adam_v	[768]
bert/encoder/layer_5/attention/output/dense/bias	[768]
bert/encoder/layer_5/attention/output/dense/bias/adam_m	[768]
bert/encoder/layer_5/attention/output/dense/bias/adam_v	[768]
bert/encoder/layer_5/attention/output/dense/kernel	[768, 768]
bert/encoder/layer_5/attention/output/dense/kernel/adam_m	[768, 768]
bert/encoder/layer_5/attention/output/dense/kernel/adam_v	[768, 768]
bert/encoder/layer_5/attention/self/key/bias	[768]
bert/encoder/layer_5/attention/self/key/bias/adam_m	[768]
bert/encoder/layer_5/attention/self/key/bias/adam_v	[768]
bert/encoder/layer_5/attention/self/key/kernel	[768, 768]
bert/encoder/layer_5/attention/self/key/kernel/adam_m	[768, 768]
bert/encoder/layer_5/attention/self/key/kernel/adam_v	[768, 768]
bert/encoder/layer_5/attention/self/query/bias	[768]
bert/encoder/layer_5/attention/self/query/bias/adam_m	[768]
bert/encoder/layer_5/attention/self/query/bias/adam_v	[768]
bert/encoder/layer_5/attention/self/query/kernel	[768, 768]
bert/encoder/layer_5/attention/self/query/kernel/adam_m	[768, 768]
bert/encoder/layer_5/attention/self/query/kernel/adam_v	[768, 768]
bert/encoder/layer_5/attention/self/value/bias	[768]
bert/encoder/layer_5/attention/self/value/bias/adam_m	[768]
bert/encoder/layer_5/attention/self/value/bias/adam_v	[768]
bert/encoder/layer_5/attention/self/value/kernel	[768, 768]
bert/encoder/layer_5/attention/self/value/kernel/adam_m	[768, 768]
bert/encoder/layer_5/attention/self/value/kernel/adam_v	[768, 768]
bert/encoder/layer_5/intermediate/dense/bias	[3072]
bert/encoder/layer_5/intermediate/dense/bias/adam_m	[3072]
bert/encoder/layer_5/intermediate/dense/bias/adam_v	[3072]
bert/encoder/layer_5/intermediate/dense/kernel	[768, 3072]
bert/encoder/layer_5/intermediate/dense/kernel/adam_m	[768, 3072]
bert/encoder/layer_5/intermediate/dense/kernel/adam_v	[768, 3072]
bert/encoder/layer_5/output/LayerNorm/beta	[768]
bert/encoder/layer_5/output/LayerNorm/beta/adam_m	[768]
bert/encoder/layer_5/output/LayerNorm/beta/adam_v	[768]
bert/encoder/layer_5/output/LayerNorm/gamma	[768]
bert/encoder/layer_5/output/LayerNorm/gamma/adam_m	[768]
bert/encoder/layer_5/output/LayerNorm/gamma/adam_v	[768]
bert/encoder/layer_5/output/dense/bias	[768]
bert/encoder/layer_5/output/dense/bias/adam_m	[768]
bert/encoder/layer_5/output/dense/bias/adam_v	[768]
bert/encoder/layer_5/output/dense/kernel	[3072, 768]
bert/encoder/layer_5/output/dense/kernel/adam_m	[3072, 768]
bert/encoder/layer_5/output/dense/kernel/adam_v	[3072, 768]
bert/encoder/layer_6/attention/output/LayerNorm/beta	[768]
bert/encoder/layer_6/attention/output/LayerNorm/beta/adam_m	[768]
bert/encoder/layer_6/attention/output/LayerNorm/beta/adam_v	[768]
bert/encoder/layer_6/attention/output/LayerNorm/gamma	[768]
bert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_m	[768]
bert/encoder/layer_6/attention/output/LayerNorm/gamma/adam_v	[768]
bert/encoder/layer_6/attention/output/dense/bias	[768]
bert/encoder/layer_6/attention/output/dense/bias/adam_m	[768]
bert/encoder/layer_6/attention/output/dense/bias/adam_v	[768]
bert/encoder/layer_6/attention/output/dense/kernel	[768, 768]
bert/encoder/layer_6/attention/output/dense/kernel/adam_m	[768, 768]
bert/encoder/layer_6/attention/output/dense/kernel/adam_v	[768, 768]
bert/encoder/layer_6/attention/self/key/bias	[768]
bert/encoder/layer_6/attention/self/key/bias/adam_m	[768]
bert/encoder/layer_6/attention/self/key/bias/adam_v	[768]
bert/encoder/layer_6/attention/self/key/kernel	[768, 768]
bert/encoder/layer_6/attention/self/key/kernel/adam_m	[768, 768]
bert/encoder/layer_6/attention/self/key/kernel/adam_v	[768, 768]
bert/encoder/layer_6/attention/self/query/bias	[768]
bert/encoder/layer_6/attention/self/query/bias/adam_m	[768]
bert/encoder/layer_6/attention/self/query/bias/adam_v	[768]
bert/encoder/layer_6/attention/self/query/kernel	[768, 768]
bert/encoder/layer_6/attention/self/query/kernel/adam_m	[768, 768]
bert/encoder/layer_6/attention/self/query/kernel/adam_v	[768, 768]
bert/encoder/layer_6/attention/self/value/bias	[768]
bert/encoder/layer_6/attention/self/value/bias/adam_m	[768]
bert/encoder/layer_6/attention/self/value/bias/adam_v	[768]
bert/encoder/layer_6/attention/self/value/kernel	[768, 768]
bert/encoder/layer_6/attention/self/value/kernel/adam_m	[768, 768]
bert/encoder/layer_6/attention/self/value/kernel/adam_v	[768, 768]
bert/encoder/layer_6/intermediate/dense/bias	[3072]
bert/encoder/layer_6/intermediate/dense/bias/adam_m	[3072]
bert/encoder/layer_6/intermediate/dense/bias/adam_v	[3072]
bert/encoder/layer_6/intermediate/dense/kernel	[768, 3072]
bert/encoder/layer_6/intermediate/dense/kernel/adam_m	[768, 3072]
bert/encoder/layer_6/intermediate/dense/kernel/adam_v	[768, 3072]
bert/encoder/layer_6/output/LayerNorm/beta	[768]
bert/encoder/layer_6/output/LayerNorm/beta/adam_m	[768]
bert/encoder/layer_6/output/LayerNorm/beta/adam_v	[768]
bert/encoder/layer_6/output/LayerNorm/gamma	[768]
bert/encoder/layer_6/output/LayerNorm/gamma/adam_m	[768]
bert/encoder/layer_6/output/LayerNorm/gamma/adam_v	[768]
bert/encoder/layer_6/output/dense/bias	[768]
bert/encoder/layer_6/output/dense/bias/adam_m	[768]
bert/encoder/layer_6/output/dense/bias/adam_v	[768]
bert/encoder/layer_6/output/dense/kernel	[3072, 768]
bert/encoder/layer_6/output/dense/kernel/adam_m	[3072, 768]
bert/encoder/layer_6/output/dense/kernel/adam_v	[3072, 768]
bert/encoder/layer_7/attention/output/LayerNorm/beta	[768]
bert/encoder/layer_7/attention/output/LayerNorm/beta/adam_m	[768]
bert/encoder/layer_7/attention/output/LayerNorm/beta/adam_v	[768]
bert/encoder/layer_7/attention/output/LayerNorm/gamma	[768]
bert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_m	[768]
bert/encoder/layer_7/attention/output/LayerNorm/gamma/adam_v	[768]
bert/encoder/layer_7/attention/output/dense/bias	[768]
bert/encoder/layer_7/attention/output/dense/bias/adam_m	[768]
bert/encoder/layer_7/attention/output/dense/bias/adam_v	[768]
bert/encoder/layer_7/attention/output/dense/kernel	[768, 768]
bert/encoder/layer_7/attention/output/dense/kernel/adam_m	[768, 768]
bert/encoder/layer_7/attention/output/dense/kernel/adam_v	[768, 768]
bert/encoder/layer_7/attention/self/key/bias	[768]
bert/encoder/layer_7/attention/self/key/bias/adam_m	[768]
bert/encoder/layer_7/attention/self/key/bias/adam_v	[768]
bert/encoder/layer_7/attention/self/key/kernel	[768, 768]
bert/encoder/layer_7/attention/self/key/kernel/adam_m	[768, 768]
bert/encoder/layer_7/attention/self/key/kernel/adam_v	[768, 768]
bert/encoder/layer_7/attention/self/query/bias	[768]
bert/encoder/layer_7/attention/self/query/bias/adam_m	[768]
bert/encoder/layer_7/attention/self/query/bias/adam_v	[768]
bert/encoder/layer_7/attention/self/query/kernel	[768, 768]
bert/encoder/layer_7/attention/self/query/kernel/adam_m	[768, 768]
bert/encoder/layer_7/attention/self/query/kernel/adam_v	[768, 768]
bert/encoder/layer_7/attention/self/value/bias	[768]
bert/encoder/layer_7/attention/self/value/bias/adam_m	[768]
bert/encoder/layer_7/attention/self/value/bias/adam_v	[768]
bert/encoder/layer_7/attention/self/value/kernel	[768, 768]
bert/encoder/layer_7/attention/self/value/kernel/adam_m	[768, 768]
bert/encoder/layer_7/attention/self/value/kernel/adam_v	[768, 768]
bert/encoder/layer_7/intermediate/dense/bias	[3072]
bert/encoder/layer_7/intermediate/dense/bias/adam_m	[3072]
bert/encoder/layer_7/intermediate/dense/bias/adam_v	[3072]
bert/encoder/layer_7/intermediate/dense/kernel	[768, 3072]
bert/encoder/layer_7/intermediate/dense/kernel/adam_m	[768, 3072]
bert/encoder/layer_7/intermediate/dense/kernel/adam_v	[768, 3072]
bert/encoder/layer_7/output/LayerNorm/beta	[768]
bert/encoder/layer_7/output/LayerNorm/beta/adam_m	[768]
bert/encoder/layer_7/output/LayerNorm/beta/adam_v	[768]
bert/encoder/layer_7/output/LayerNorm/gamma	[768]
bert/encoder/layer_7/output/LayerNorm/gamma/adam_m	[768]
bert/encoder/layer_7/output/LayerNorm/gamma/adam_v	[768]
bert/encoder/layer_7/output/dense/bias	[768]
bert/encoder/layer_7/output/dense/bias/adam_m	[768]
bert/encoder/layer_7/output/dense/bias/adam_v	[768]
bert/encoder/layer_7/output/dense/kernel	[3072, 768]
bert/encoder/layer_7/output/dense/kernel/adam_m	[3072, 768]
bert/encoder/layer_7/output/dense/kernel/adam_v	[3072, 768]
bert/encoder/layer_8/attention/output/LayerNorm/beta	[768]
bert/encoder/layer_8/attention/output/LayerNorm/beta/adam_m	[768]
bert/encoder/layer_8/attention/output/LayerNorm/beta/adam_v	[768]
bert/encoder/layer_8/attention/output/LayerNorm/gamma	[768]
bert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_m	[768]
bert/encoder/layer_8/attention/output/LayerNorm/gamma/adam_v	[768]
bert/encoder/layer_8/attention/output/dense/bias	[768]
bert/encoder/layer_8/attention/output/dense/bias/adam_m	[768]
bert/encoder/layer_8/attention/output/dense/bias/adam_v	[768]
bert/encoder/layer_8/attention/output/dense/kernel	[768, 768]
bert/encoder/layer_8/attention/output/dense/kernel/adam_m	[768, 768]
bert/encoder/layer_8/attention/output/dense/kernel/adam_v	[768, 768]
bert/encoder/layer_8/attention/self/key/bias	[768]
bert/encoder/layer_8/attention/self/key/bias/adam_m	[768]
bert/encoder/layer_8/attention/self/key/bias/adam_v	[768]
bert/encoder/layer_8/attention/self/key/kernel	[768, 768]
bert/encoder/layer_8/attention/self/key/kernel/adam_m	[768, 768]
bert/encoder/layer_8/attention/self/key/kernel/adam_v	[768, 768]
bert/encoder/layer_8/attention/self/query/bias	[768]
bert/encoder/layer_8/attention/self/query/bias/adam_m	[768]
bert/encoder/layer_8/attention/self/query/bias/adam_v	[768]
bert/encoder/layer_8/attention/self/query/kernel	[768, 768]
bert/encoder/layer_8/attention/self/query/kernel/adam_m	[768, 768]
bert/encoder/layer_8/attention/self/query/kernel/adam_v	[768, 768]
bert/encoder/layer_8/attention/self/value/bias	[768]
bert/encoder/layer_8/attention/self/value/bias/adam_m	[768]
bert/encoder/layer_8/attention/self/value/bias/adam_v	[768]
bert/encoder/layer_8/attention/self/value/kernel	[768, 768]
bert/encoder/layer_8/attention/self/value/kernel/adam_m	[768, 768]
bert/encoder/layer_8/attention/self/value/kernel/adam_v	[768, 768]
bert/encoder/layer_8/intermediate/dense/bias	[3072]
bert/encoder/layer_8/intermediate/dense/bias/adam_m	[3072]
bert/encoder/layer_8/intermediate/dense/bias/adam_v	[3072]
bert/encoder/layer_8/intermediate/dense/kernel	[768, 3072]
bert/encoder/layer_8/intermediate/dense/kernel/adam_m	[768, 3072]
bert/encoder/layer_8/intermediate/dense/kernel/adam_v	[768, 3072]
bert/encoder/layer_8/output/LayerNorm/beta	[768]
bert/encoder/layer_8/output/LayerNorm/beta/adam_m	[768]
bert/encoder/layer_8/output/LayerNorm/beta/adam_v	[768]
bert/encoder/layer_8/output/LayerNorm/gamma	[768]
bert/encoder/layer_8/output/LayerNorm/gamma/adam_m	[768]
bert/encoder/layer_8/output/LayerNorm/gamma/adam_v	[768]
bert/encoder/layer_8/output/dense/bias	[768]
bert/encoder/layer_8/output/dense/bias/adam_m	[768]
bert/encoder/layer_8/output/dense/bias/adam_v	[768]
bert/encoder/layer_8/output/dense/kernel	[3072, 768]
bert/encoder/layer_8/output/dense/kernel/adam_m	[3072, 768]
bert/encoder/layer_8/output/dense/kernel/adam_v	[3072, 768]
bert/encoder/layer_9/attention/output/LayerNorm/beta	[768]
bert/encoder/layer_9/attention/output/LayerNorm/beta/adam_m	[768]
bert/encoder/layer_9/attention/output/LayerNorm/beta/adam_v	[768]
bert/encoder/layer_9/attention/output/LayerNorm/gamma	[768]
bert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_m	[768]
bert/encoder/layer_9/attention/output/LayerNorm/gamma/adam_v	[768]
bert/encoder/layer_9/attention/output/dense/bias	[768]
bert/encoder/layer_9/attention/output/dense/bias/adam_m	[768]
bert/encoder/layer_9/attention/output/dense/bias/adam_v	[768]
bert/encoder/layer_9/attention/output/dense/kernel	[768, 768]
bert/encoder/layer_9/attention/output/dense/kernel/adam_m	[768, 768]
bert/encoder/layer_9/attention/output/dense/kernel/adam_v	[768, 768]
bert/encoder/layer_9/attention/self/key/bias	[768]
bert/encoder/layer_9/attention/self/key/bias/adam_m	[768]
bert/encoder/layer_9/attention/self/key/bias/adam_v	[768]
bert/encoder/layer_9/attention/self/key/kernel	[768, 768]
bert/encoder/layer_9/attention/self/key/kernel/adam_m	[768, 768]
bert/encoder/layer_9/attention/self/key/kernel/adam_v	[768, 768]
bert/encoder/layer_9/attention/self/query/bias	[768]
bert/encoder/layer_9/attention/self/query/bias/adam_m	[768]
bert/encoder/layer_9/attention/self/query/bias/adam_v	[768]
bert/encoder/layer_9/attention/self/query/kernel	[768, 768]
bert/encoder/layer_9/attention/self/query/kernel/adam_m	[768, 768]
bert/encoder/layer_9/attention/self/query/kernel/adam_v	[768, 768]
bert/encoder/layer_9/attention/self/value/bias	[768]
bert/encoder/layer_9/attention/self/value/bias/adam_m	[768]
bert/encoder/layer_9/attention/self/value/bias/adam_v	[768]
bert/encoder/layer_9/attention/self/value/kernel	[768, 768]
bert/encoder/layer_9/attention/self/value/kernel/adam_m	[768, 768]
bert/encoder/layer_9/attention/self/value/kernel/adam_v	[768, 768]
bert/encoder/layer_9/intermediate/dense/bias	[3072]
bert/encoder/layer_9/intermediate/dense/bias/adam_m	[3072]
bert/encoder/layer_9/intermediate/dense/bias/adam_v	[3072]
bert/encoder/layer_9/intermediate/dense/kernel	[768, 3072]
bert/encoder/layer_9/intermediate/dense/kernel/adam_m	[768, 3072]
bert/encoder/layer_9/intermediate/dense/kernel/adam_v	[768, 3072]
bert/encoder/layer_9/output/LayerNorm/beta	[768]
bert/encoder/layer_9/output/LayerNorm/beta/adam_m	[768]
bert/encoder/layer_9/output/LayerNorm/beta/adam_v	[768]
bert/encoder/layer_9/output/LayerNorm/gamma	[768]
bert/encoder/layer_9/output/LayerNorm/gamma/adam_m	[768]
bert/encoder/layer_9/output/LayerNorm/gamma/adam_v	[768]
bert/encoder/layer_9/output/dense/bias	[768]
bert/encoder/layer_9/output/dense/bias/adam_m	[768]
bert/encoder/layer_9/output/dense/bias/adam_v	[768]
bert/encoder/layer_9/output/dense/kernel	[3072, 768]
bert/encoder/layer_9/output/dense/kernel/adam_m	[3072, 768]
bert/encoder/layer_9/output/dense/kernel/adam_v	[3072, 768]
bert/pooler/dense/bias	[768]
bert/pooler/dense/kernel	[768, 768]
decode/copy/copy_gate/linear/W	[768, 1]
decode/copy/copy_gate/linear/W/adam_m	[768, 1]
decode/copy/copy_gate/linear/W/adam_v	[768, 1]
decode/copy/copy_gate/linear/b	[1]
decode/copy/copy_gate/linear/b/adam_m	[1]
decode/copy/copy_gate/linear/b/adam_v	[1]
decode/decoder/layer_0/encdec_attention/layer_norm/bias	[768]
decode/decoder/layer_0/encdec_attention/layer_norm/bias/adam_m	[768]
decode/decoder/layer_0/encdec_attention/layer_norm/bias/adam_v	[768]
decode/decoder/layer_0/encdec_attention/layer_norm/scale	[768]
decode/decoder/layer_0/encdec_attention/layer_norm/scale/adam_m	[768]
decode/decoder/layer_0/encdec_attention/layer_norm/scale/adam_v	[768]
decode/decoder/layer_0/encdec_attention/multihead_attention/kv_transform/W	[768, 1536]
decode/decoder/layer_0/encdec_attention/multihead_attention/kv_transform/W/adam_m	[768, 1536]
decode/decoder/layer_0/encdec_attention/multihead_attention/kv_transform/W/adam_v	[768, 1536]
decode/decoder/layer_0/encdec_attention/multihead_attention/kv_transform/b	[1536]
decode/decoder/layer_0/encdec_attention/multihead_attention/kv_transform/b/adam_m	[1536]
decode/decoder/layer_0/encdec_attention/multihead_attention/kv_transform/b/adam_v	[1536]
decode/decoder/layer_0/encdec_attention/multihead_attention/output_transform/W	[768, 768]
decode/decoder/layer_0/encdec_attention/multihead_attention/output_transform/W/adam_m	[768, 768]
decode/decoder/layer_0/encdec_attention/multihead_attention/output_transform/W/adam_v	[768, 768]
decode/decoder/layer_0/encdec_attention/multihead_attention/output_transform/b	[768]
decode/decoder/layer_0/encdec_attention/multihead_attention/output_transform/b/adam_m	[768]
decode/decoder/layer_0/encdec_attention/multihead_attention/output_transform/b/adam_v	[768]
decode/decoder/layer_0/encdec_attention/multihead_attention/q_transform/W	[768, 768]
decode/decoder/layer_0/encdec_attention/multihead_attention/q_transform/W/adam_m	[768, 768]
decode/decoder/layer_0/encdec_attention/multihead_attention/q_transform/W/adam_v	[768, 768]
decode/decoder/layer_0/encdec_attention/multihead_attention/q_transform/b	[768]
decode/decoder/layer_0/encdec_attention/multihead_attention/q_transform/b/adam_m	[768]
decode/decoder/layer_0/encdec_attention/multihead_attention/q_transform/b/adam_v	[768]
decode/decoder/layer_0/feed_forward/ffn_layer/input_layer/linear/W	[768, 3072]
decode/decoder/layer_0/feed_forward/ffn_layer/input_layer/linear/W/adam_m	[768, 3072]
decode/decoder/layer_0/feed_forward/ffn_layer/input_layer/linear/W/adam_v	[768, 3072]
decode/decoder/layer_0/feed_forward/ffn_layer/input_layer/linear/b	[3072]
decode/decoder/layer_0/feed_forward/ffn_layer/input_layer/linear/b/adam_m	[3072]
decode/decoder/layer_0/feed_forward/ffn_layer/input_layer/linear/b/adam_v	[3072]
decode/decoder/layer_0/feed_forward/ffn_layer/output_layer/linear/W	[3072, 768]
decode/decoder/layer_0/feed_forward/ffn_layer/output_layer/linear/W/adam_m	[3072, 768]
decode/decoder/layer_0/feed_forward/ffn_layer/output_layer/linear/W/adam_v	[3072, 768]
decode/decoder/layer_0/feed_forward/ffn_layer/output_layer/linear/b	[768]
decode/decoder/layer_0/feed_forward/ffn_layer/output_layer/linear/b/adam_m	[768]
decode/decoder/layer_0/feed_forward/ffn_layer/output_layer/linear/b/adam_v	[768]
decode/decoder/layer_0/feed_forward/layer_norm/bias	[768]
decode/decoder/layer_0/feed_forward/layer_norm/bias/adam_m	[768]
decode/decoder/layer_0/feed_forward/layer_norm/bias/adam_v	[768]
decode/decoder/layer_0/feed_forward/layer_norm/scale	[768]
decode/decoder/layer_0/feed_forward/layer_norm/scale/adam_m	[768]
decode/decoder/layer_0/feed_forward/layer_norm/scale/adam_v	[768]
decode/decoder/layer_0/self_attention/layer_norm/bias	[768]
decode/decoder/layer_0/self_attention/layer_norm/bias/adam_m	[768]
decode/decoder/layer_0/self_attention/layer_norm/bias/adam_v	[768]
decode/decoder/layer_0/self_attention/layer_norm/scale	[768]
decode/decoder/layer_0/self_attention/layer_norm/scale/adam_m	[768]
decode/decoder/layer_0/self_attention/layer_norm/scale/adam_v	[768]
decode/decoder/layer_0/self_attention/multihead_attention/output_transform/W	[768, 768]
decode/decoder/layer_0/self_attention/multihead_attention/output_transform/W/adam_m	[768, 768]
decode/decoder/layer_0/self_attention/multihead_attention/output_transform/W/adam_v	[768, 768]
decode/decoder/layer_0/self_attention/multihead_attention/output_transform/b	[768]
decode/decoder/layer_0/self_attention/multihead_attention/output_transform/b/adam_m	[768]
decode/decoder/layer_0/self_attention/multihead_attention/output_transform/b/adam_v	[768]
decode/decoder/layer_0/self_attention/multihead_attention/qkv_transform/W	[768, 2304]
decode/decoder/layer_0/self_attention/multihead_attention/qkv_transform/W/adam_m	[768, 2304]
decode/decoder/layer_0/self_attention/multihead_attention/qkv_transform/W/adam_v	[768, 2304]
decode/decoder/layer_0/self_attention/multihead_attention/qkv_transform/b	[2304]
decode/decoder/layer_0/self_attention/multihead_attention/qkv_transform/b/adam_m	[2304]
decode/decoder/layer_0/self_attention/multihead_attention/qkv_transform/b/adam_v	[2304]
decode/decoder/layer_1/encdec_attention/layer_norm/bias	[768]
decode/decoder/layer_1/encdec_attention/layer_norm/bias/adam_m	[768]
decode/decoder/layer_1/encdec_attention/layer_norm/bias/adam_v	[768]
decode/decoder/layer_1/encdec_attention/layer_norm/scale	[768]
decode/decoder/layer_1/encdec_attention/layer_norm/scale/adam_m	[768]
decode/decoder/layer_1/encdec_attention/layer_norm/scale/adam_v	[768]
decode/decoder/layer_1/encdec_attention/multihead_attention/kv_transform/W	[768, 1536]
decode/decoder/layer_1/encdec_attention/multihead_attention/kv_transform/W/adam_m	[768, 1536]
decode/decoder/layer_1/encdec_attention/multihead_attention/kv_transform/W/adam_v	[768, 1536]
decode/decoder/layer_1/encdec_attention/multihead_attention/kv_transform/b	[1536]
decode/decoder/layer_1/encdec_attention/multihead_attention/kv_transform/b/adam_m	[1536]
decode/decoder/layer_1/encdec_attention/multihead_attention/kv_transform/b/adam_v	[1536]
decode/decoder/layer_1/encdec_attention/multihead_attention/output_transform/W	[768, 768]
decode/decoder/layer_1/encdec_attention/multihead_attention/output_transform/W/adam_m	[768, 768]
decode/decoder/layer_1/encdec_attention/multihead_attention/output_transform/W/adam_v	[768, 768]
decode/decoder/layer_1/encdec_attention/multihead_attention/output_transform/b	[768]
decode/decoder/layer_1/encdec_attention/multihead_attention/output_transform/b/adam_m	[768]
decode/decoder/layer_1/encdec_attention/multihead_attention/output_transform/b/adam_v	[768]
decode/decoder/layer_1/encdec_attention/multihead_attention/q_transform/W	[768, 768]
decode/decoder/layer_1/encdec_attention/multihead_attention/q_transform/W/adam_m	[768, 768]
decode/decoder/layer_1/encdec_attention/multihead_attention/q_transform/W/adam_v	[768, 768]
decode/decoder/layer_1/encdec_attention/multihead_attention/q_transform/b	[768]
decode/decoder/layer_1/encdec_attention/multihead_attention/q_transform/b/adam_m	[768]
decode/decoder/layer_1/encdec_attention/multihead_attention/q_transform/b/adam_v	[768]
decode/decoder/layer_1/feed_forward/ffn_layer/input_layer/linear/W	[768, 3072]
decode/decoder/layer_1/feed_forward/ffn_layer/input_layer/linear/W/adam_m	[768, 3072]
decode/decoder/layer_1/feed_forward/ffn_layer/input_layer/linear/W/adam_v	[768, 3072]
decode/decoder/layer_1/feed_forward/ffn_layer/input_layer/linear/b	[3072]
decode/decoder/layer_1/feed_forward/ffn_layer/input_layer/linear/b/adam_m	[3072]
decode/decoder/layer_1/feed_forward/ffn_layer/input_layer/linear/b/adam_v	[3072]
decode/decoder/layer_1/feed_forward/ffn_layer/output_layer/linear/W	[3072, 768]
decode/decoder/layer_1/feed_forward/ffn_layer/output_layer/linear/W/adam_m	[3072, 768]
decode/decoder/layer_1/feed_forward/ffn_layer/output_layer/linear/W/adam_v	[3072, 768]
decode/decoder/layer_1/feed_forward/ffn_layer/output_layer/linear/b	[768]
decode/decoder/layer_1/feed_forward/ffn_layer/output_layer/linear/b/adam_m	[768]
decode/decoder/layer_1/feed_forward/ffn_layer/output_layer/linear/b/adam_v	[768]
decode/decoder/layer_1/feed_forward/layer_norm/bias	[768]
decode/decoder/layer_1/feed_forward/layer_norm/bias/adam_m	[768]
decode/decoder/layer_1/feed_forward/layer_norm/bias/adam_v	[768]
decode/decoder/layer_1/feed_forward/layer_norm/scale	[768]
decode/decoder/layer_1/feed_forward/layer_norm/scale/adam_m	[768]
decode/decoder/layer_1/feed_forward/layer_norm/scale/adam_v	[768]
decode/decoder/layer_1/self_attention/layer_norm/bias	[768]
decode/decoder/layer_1/self_attention/layer_norm/bias/adam_m	[768]
decode/decoder/layer_1/self_attention/layer_norm/bias/adam_v	[768]
decode/decoder/layer_1/self_attention/layer_norm/scale	[768]
decode/decoder/layer_1/self_attention/layer_norm/scale/adam_m	[768]
decode/decoder/layer_1/self_attention/layer_norm/scale/adam_v	[768]
decode/decoder/layer_1/self_attention/multihead_attention/output_transform/W	[768, 768]
decode/decoder/layer_1/self_attention/multihead_attention/output_transform/W/adam_m	[768, 768]
decode/decoder/layer_1/self_attention/multihead_attention/output_transform/W/adam_v	[768, 768]
decode/decoder/layer_1/self_attention/multihead_attention/output_transform/b	[768]
decode/decoder/layer_1/self_attention/multihead_attention/output_transform/b/adam_m	[768]
decode/decoder/layer_1/self_attention/multihead_attention/output_transform/b/adam_v	[768]
decode/decoder/layer_1/self_attention/multihead_attention/qkv_transform/W	[768, 2304]
decode/decoder/layer_1/self_attention/multihead_attention/qkv_transform/W/adam_m	[768, 2304]
decode/decoder/layer_1/self_attention/multihead_attention/qkv_transform/W/adam_v	[768, 2304]
decode/decoder/layer_1/self_attention/multihead_attention/qkv_transform/b	[2304]
decode/decoder/layer_1/self_attention/multihead_attention/qkv_transform/b/adam_m	[2304]
decode/decoder/layer_1/self_attention/multihead_attention/qkv_transform/b/adam_v	[2304]
decode/decoder/layer_10/encdec_attention/layer_norm/bias	[768]
decode/decoder/layer_10/encdec_attention/layer_norm/bias/adam_m	[768]
decode/decoder/layer_10/encdec_attention/layer_norm/bias/adam_v	[768]
decode/decoder/layer_10/encdec_attention/layer_norm/scale	[768]
decode/decoder/layer_10/encdec_attention/layer_norm/scale/adam_m	[768]
decode/decoder/layer_10/encdec_attention/layer_norm/scale/adam_v	[768]
decode/decoder/layer_10/encdec_attention/multihead_attention/kv_transform/W	[768, 1536]
decode/decoder/layer_10/encdec_attention/multihead_attention/kv_transform/W/adam_m	[768, 1536]
decode/decoder/layer_10/encdec_attention/multihead_attention/kv_transform/W/adam_v	[768, 1536]
decode/decoder/layer_10/encdec_attention/multihead_attention/kv_transform/b	[1536]
decode/decoder/layer_10/encdec_attention/multihead_attention/kv_transform/b/adam_m	[1536]
decode/decoder/layer_10/encdec_attention/multihead_attention/kv_transform/b/adam_v	[1536]
decode/decoder/layer_10/encdec_attention/multihead_attention/output_transform/W	[768, 768]
decode/decoder/layer_10/encdec_attention/multihead_attention/output_transform/W/adam_m	[768, 768]
decode/decoder/layer_10/encdec_attention/multihead_attention/output_transform/W/adam_v	[768, 768]
decode/decoder/layer_10/encdec_attention/multihead_attention/output_transform/b	[768]
decode/decoder/layer_10/encdec_attention/multihead_attention/output_transform/b/adam_m	[768]
decode/decoder/layer_10/encdec_attention/multihead_attention/output_transform/b/adam_v	[768]
decode/decoder/layer_10/encdec_attention/multihead_attention/q_transform/W	[768, 768]
decode/decoder/layer_10/encdec_attention/multihead_attention/q_transform/W/adam_m	[768, 768]
decode/decoder/layer_10/encdec_attention/multihead_attention/q_transform/W/adam_v	[768, 768]
decode/decoder/layer_10/encdec_attention/multihead_attention/q_transform/b	[768]
decode/decoder/layer_10/encdec_attention/multihead_attention/q_transform/b/adam_m	[768]
decode/decoder/layer_10/encdec_attention/multihead_attention/q_transform/b/adam_v	[768]
decode/decoder/layer_10/feed_forward/ffn_layer/input_layer/linear/W	[768, 3072]
decode/decoder/layer_10/feed_forward/ffn_layer/input_layer/linear/W/adam_m	[768, 3072]
decode/decoder/layer_10/feed_forward/ffn_layer/input_layer/linear/W/adam_v	[768, 3072]
decode/decoder/layer_10/feed_forward/ffn_layer/input_layer/linear/b	[3072]
decode/decoder/layer_10/feed_forward/ffn_layer/input_layer/linear/b/adam_m	[3072]
decode/decoder/layer_10/feed_forward/ffn_layer/input_layer/linear/b/adam_v	[3072]
decode/decoder/layer_10/feed_forward/ffn_layer/output_layer/linear/W	[3072, 768]
decode/decoder/layer_10/feed_forward/ffn_layer/output_layer/linear/W/adam_m	[3072, 768]
decode/decoder/layer_10/feed_forward/ffn_layer/output_layer/linear/W/adam_v	[3072, 768]
decode/decoder/layer_10/feed_forward/ffn_layer/output_layer/linear/b	[768]
decode/decoder/layer_10/feed_forward/ffn_layer/output_layer/linear/b/adam_m	[768]
decode/decoder/layer_10/feed_forward/ffn_layer/output_layer/linear/b/adam_v	[768]
decode/decoder/layer_10/feed_forward/layer_norm/bias	[768]
decode/decoder/layer_10/feed_forward/layer_norm/bias/adam_m	[768]
decode/decoder/layer_10/feed_forward/layer_norm/bias/adam_v	[768]
decode/decoder/layer_10/feed_forward/layer_norm/scale	[768]
decode/decoder/layer_10/feed_forward/layer_norm/scale/adam_m	[768]
decode/decoder/layer_10/feed_forward/layer_norm/scale/adam_v	[768]
decode/decoder/layer_10/self_attention/layer_norm/bias	[768]
decode/decoder/layer_10/self_attention/layer_norm/bias/adam_m	[768]
decode/decoder/layer_10/self_attention/layer_norm/bias/adam_v	[768]
decode/decoder/layer_10/self_attention/layer_norm/scale	[768]
decode/decoder/layer_10/self_attention/layer_norm/scale/adam_m	[768]
decode/decoder/layer_10/self_attention/layer_norm/scale/adam_v	[768]
decode/decoder/layer_10/self_attention/multihead_attention/output_transform/W	[768, 768]
decode/decoder/layer_10/self_attention/multihead_attention/output_transform/W/adam_m	[768, 768]
decode/decoder/layer_10/self_attention/multihead_attention/output_transform/W/adam_v	[768, 768]
decode/decoder/layer_10/self_attention/multihead_attention/output_transform/b	[768]
decode/decoder/layer_10/self_attention/multihead_attention/output_transform/b/adam_m	[768]
decode/decoder/layer_10/self_attention/multihead_attention/output_transform/b/adam_v	[768]
decode/decoder/layer_10/self_attention/multihead_attention/qkv_transform/W	[768, 2304]
decode/decoder/layer_10/self_attention/multihead_attention/qkv_transform/W/adam_m	[768, 2304]
decode/decoder/layer_10/self_attention/multihead_attention/qkv_transform/W/adam_v	[768, 2304]
decode/decoder/layer_10/self_attention/multihead_attention/qkv_transform/b	[2304]
decode/decoder/layer_10/self_attention/multihead_attention/qkv_transform/b/adam_m	[2304]
decode/decoder/layer_10/self_attention/multihead_attention/qkv_transform/b/adam_v	[2304]
decode/decoder/layer_11/encdec_attention/layer_norm/bias	[768]
decode/decoder/layer_11/encdec_attention/layer_norm/bias/adam_m	[768]
decode/decoder/layer_11/encdec_attention/layer_norm/bias/adam_v	[768]
decode/decoder/layer_11/encdec_attention/layer_norm/scale	[768]
decode/decoder/layer_11/encdec_attention/layer_norm/scale/adam_m	[768]
decode/decoder/layer_11/encdec_attention/layer_norm/scale/adam_v	[768]
decode/decoder/layer_11/encdec_attention/multihead_attention/kv_transform/W	[768, 1536]
decode/decoder/layer_11/encdec_attention/multihead_attention/kv_transform/W/adam_m	[768, 1536]
decode/decoder/layer_11/encdec_attention/multihead_attention/kv_transform/W/adam_v	[768, 1536]
decode/decoder/layer_11/encdec_attention/multihead_attention/kv_transform/b	[1536]
decode/decoder/layer_11/encdec_attention/multihead_attention/kv_transform/b/adam_m	[1536]
decode/decoder/layer_11/encdec_attention/multihead_attention/kv_transform/b/adam_v	[1536]
decode/decoder/layer_11/encdec_attention/multihead_attention/output_transform/W	[768, 768]
decode/decoder/layer_11/encdec_attention/multihead_attention/output_transform/W/adam_m	[768, 768]
decode/decoder/layer_11/encdec_attention/multihead_attention/output_transform/W/adam_v	[768, 768]
decode/decoder/layer_11/encdec_attention/multihead_attention/output_transform/b	[768]
decode/decoder/layer_11/encdec_attention/multihead_attention/output_transform/b/adam_m	[768]
decode/decoder/layer_11/encdec_attention/multihead_attention/output_transform/b/adam_v	[768]
decode/decoder/layer_11/encdec_attention/multihead_attention/q_transform/W	[768, 768]
decode/decoder/layer_11/encdec_attention/multihead_attention/q_transform/W/adam_m	[768, 768]
decode/decoder/layer_11/encdec_attention/multihead_attention/q_transform/W/adam_v	[768, 768]
decode/decoder/layer_11/encdec_attention/multihead_attention/q_transform/b	[768]
decode/decoder/layer_11/encdec_attention/multihead_attention/q_transform/b/adam_m	[768]
decode/decoder/layer_11/encdec_attention/multihead_attention/q_transform/b/adam_v	[768]
decode/decoder/layer_11/feed_forward/ffn_layer/input_layer/linear/W	[768, 3072]
decode/decoder/layer_11/feed_forward/ffn_layer/input_layer/linear/W/adam_m	[768, 3072]
decode/decoder/layer_11/feed_forward/ffn_layer/input_layer/linear/W/adam_v	[768, 3072]
decode/decoder/layer_11/feed_forward/ffn_layer/input_layer/linear/b	[3072]
decode/decoder/layer_11/feed_forward/ffn_layer/input_layer/linear/b/adam_m	[3072]
decode/decoder/layer_11/feed_forward/ffn_layer/input_layer/linear/b/adam_v	[3072]
decode/decoder/layer_11/feed_forward/ffn_layer/output_layer/linear/W	[3072, 768]
decode/decoder/layer_11/feed_forward/ffn_layer/output_layer/linear/W/adam_m	[3072, 768]
decode/decoder/layer_11/feed_forward/ffn_layer/output_layer/linear/W/adam_v	[3072, 768]
decode/decoder/layer_11/feed_forward/ffn_layer/output_layer/linear/b	[768]
decode/decoder/layer_11/feed_forward/ffn_layer/output_layer/linear/b/adam_m	[768]
decode/decoder/layer_11/feed_forward/ffn_layer/output_layer/linear/b/adam_v	[768]
decode/decoder/layer_11/feed_forward/layer_norm/bias	[768]
decode/decoder/layer_11/feed_forward/layer_norm/bias/adam_m	[768]
decode/decoder/layer_11/feed_forward/layer_norm/bias/adam_v	[768]
decode/decoder/layer_11/feed_forward/layer_norm/scale	[768]
decode/decoder/layer_11/feed_forward/layer_norm/scale/adam_m	[768]
decode/decoder/layer_11/feed_forward/layer_norm/scale/adam_v	[768]
decode/decoder/layer_11/self_attention/layer_norm/bias	[768]
decode/decoder/layer_11/self_attention/layer_norm/bias/adam_m	[768]
decode/decoder/layer_11/self_attention/layer_norm/bias/adam_v	[768]
decode/decoder/layer_11/self_attention/layer_norm/scale	[768]
decode/decoder/layer_11/self_attention/layer_norm/scale/adam_m	[768]
decode/decoder/layer_11/self_attention/layer_norm/scale/adam_v	[768]
decode/decoder/layer_11/self_attention/multihead_attention/output_transform/W	[768, 768]
decode/decoder/layer_11/self_attention/multihead_attention/output_transform/W/adam_m	[768, 768]
decode/decoder/layer_11/self_attention/multihead_attention/output_transform/W/adam_v	[768, 768]
decode/decoder/layer_11/self_attention/multihead_attention/output_transform/b	[768]
decode/decoder/layer_11/self_attention/multihead_attention/output_transform/b/adam_m	[768]
decode/decoder/layer_11/self_attention/multihead_attention/output_transform/b/adam_v	[768]
decode/decoder/layer_11/self_attention/multihead_attention/qkv_transform/W	[768, 2304]
decode/decoder/layer_11/self_attention/multihead_attention/qkv_transform/W/adam_m	[768, 2304]
decode/decoder/layer_11/self_attention/multihead_attention/qkv_transform/W/adam_v	[768, 2304]
decode/decoder/layer_11/self_attention/multihead_attention/qkv_transform/b	[2304]
decode/decoder/layer_11/self_attention/multihead_attention/qkv_transform/b/adam_m	[2304]
decode/decoder/layer_11/self_attention/multihead_attention/qkv_transform/b/adam_v	[2304]
decode/decoder/layer_2/encdec_attention/layer_norm/bias	[768]
decode/decoder/layer_2/encdec_attention/layer_norm/bias/adam_m	[768]
decode/decoder/layer_2/encdec_attention/layer_norm/bias/adam_v	[768]
decode/decoder/layer_2/encdec_attention/layer_norm/scale	[768]
decode/decoder/layer_2/encdec_attention/layer_norm/scale/adam_m	[768]
decode/decoder/layer_2/encdec_attention/layer_norm/scale/adam_v	[768]
decode/decoder/layer_2/encdec_attention/multihead_attention/kv_transform/W	[768, 1536]
decode/decoder/layer_2/encdec_attention/multihead_attention/kv_transform/W/adam_m	[768, 1536]
decode/decoder/layer_2/encdec_attention/multihead_attention/kv_transform/W/adam_v	[768, 1536]
decode/decoder/layer_2/encdec_attention/multihead_attention/kv_transform/b	[1536]
decode/decoder/layer_2/encdec_attention/multihead_attention/kv_transform/b/adam_m	[1536]
decode/decoder/layer_2/encdec_attention/multihead_attention/kv_transform/b/adam_v	[1536]
decode/decoder/layer_2/encdec_attention/multihead_attention/output_transform/W	[768, 768]
decode/decoder/layer_2/encdec_attention/multihead_attention/output_transform/W/adam_m	[768, 768]
decode/decoder/layer_2/encdec_attention/multihead_attention/output_transform/W/adam_v	[768, 768]
decode/decoder/layer_2/encdec_attention/multihead_attention/output_transform/b	[768]
decode/decoder/layer_2/encdec_attention/multihead_attention/output_transform/b/adam_m	[768]
decode/decoder/layer_2/encdec_attention/multihead_attention/output_transform/b/adam_v	[768]
decode/decoder/layer_2/encdec_attention/multihead_attention/q_transform/W	[768, 768]
decode/decoder/layer_2/encdec_attention/multihead_attention/q_transform/W/adam_m	[768, 768]
decode/decoder/layer_2/encdec_attention/multihead_attention/q_transform/W/adam_v	[768, 768]
decode/decoder/layer_2/encdec_attention/multihead_attention/q_transform/b	[768]
decode/decoder/layer_2/encdec_attention/multihead_attention/q_transform/b/adam_m	[768]
decode/decoder/layer_2/encdec_attention/multihead_attention/q_transform/b/adam_v	[768]
decode/decoder/layer_2/feed_forward/ffn_layer/input_layer/linear/W	[768, 3072]
decode/decoder/layer_2/feed_forward/ffn_layer/input_layer/linear/W/adam_m	[768, 3072]
decode/decoder/layer_2/feed_forward/ffn_layer/input_layer/linear/W/adam_v	[768, 3072]
decode/decoder/layer_2/feed_forward/ffn_layer/input_layer/linear/b	[3072]
decode/decoder/layer_2/feed_forward/ffn_layer/input_layer/linear/b/adam_m	[3072]
decode/decoder/layer_2/feed_forward/ffn_layer/input_layer/linear/b/adam_v	[3072]
decode/decoder/layer_2/feed_forward/ffn_layer/output_layer/linear/W	[3072, 768]
decode/decoder/layer_2/feed_forward/ffn_layer/output_layer/linear/W/adam_m	[3072, 768]
decode/decoder/layer_2/feed_forward/ffn_layer/output_layer/linear/W/adam_v	[3072, 768]
decode/decoder/layer_2/feed_forward/ffn_layer/output_layer/linear/b	[768]
decode/decoder/layer_2/feed_forward/ffn_layer/output_layer/linear/b/adam_m	[768]
decode/decoder/layer_2/feed_forward/ffn_layer/output_layer/linear/b/adam_v	[768]
decode/decoder/layer_2/feed_forward/layer_norm/bias	[768]
decode/decoder/layer_2/feed_forward/layer_norm/bias/adam_m	[768]
decode/decoder/layer_2/feed_forward/layer_norm/bias/adam_v	[768]
decode/decoder/layer_2/feed_forward/layer_norm/scale	[768]
decode/decoder/layer_2/feed_forward/layer_norm/scale/adam_m	[768]
decode/decoder/layer_2/feed_forward/layer_norm/scale/adam_v	[768]
decode/decoder/layer_2/self_attention/layer_norm/bias	[768]
decode/decoder/layer_2/self_attention/layer_norm/bias/adam_m	[768]
decode/decoder/layer_2/self_attention/layer_norm/bias/adam_v	[768]
decode/decoder/layer_2/self_attention/layer_norm/scale	[768]
decode/decoder/layer_2/self_attention/layer_norm/scale/adam_m	[768]
decode/decoder/layer_2/self_attention/layer_norm/scale/adam_v	[768]
decode/decoder/layer_2/self_attention/multihead_attention/output_transform/W	[768, 768]
decode/decoder/layer_2/self_attention/multihead_attention/output_transform/W/adam_m	[768, 768]
decode/decoder/layer_2/self_attention/multihead_attention/output_transform/W/adam_v	[768, 768]
decode/decoder/layer_2/self_attention/multihead_attention/output_transform/b	[768]
decode/decoder/layer_2/self_attention/multihead_attention/output_transform/b/adam_m	[768]
decode/decoder/layer_2/self_attention/multihead_attention/output_transform/b/adam_v	[768]
decode/decoder/layer_2/self_attention/multihead_attention/qkv_transform/W	[768, 2304]
decode/decoder/layer_2/self_attention/multihead_attention/qkv_transform/W/adam_m	[768, 2304]
decode/decoder/layer_2/self_attention/multihead_attention/qkv_transform/W/adam_v	[768, 2304]
decode/decoder/layer_2/self_attention/multihead_attention/qkv_transform/b	[2304]
decode/decoder/layer_2/self_attention/multihead_attention/qkv_transform/b/adam_m	[2304]
decode/decoder/layer_2/self_attention/multihead_attention/qkv_transform/b/adam_v	[2304]
decode/decoder/layer_3/encdec_attention/layer_norm/bias	[768]
decode/decoder/layer_3/encdec_attention/layer_norm/bias/adam_m	[768]
decode/decoder/layer_3/encdec_attention/layer_norm/bias/adam_v	[768]
decode/decoder/layer_3/encdec_attention/layer_norm/scale	[768]
decode/decoder/layer_3/encdec_attention/layer_norm/scale/adam_m	[768]
decode/decoder/layer_3/encdec_attention/layer_norm/scale/adam_v	[768]
decode/decoder/layer_3/encdec_attention/multihead_attention/kv_transform/W	[768, 1536]
decode/decoder/layer_3/encdec_attention/multihead_attention/kv_transform/W/adam_m	[768, 1536]
decode/decoder/layer_3/encdec_attention/multihead_attention/kv_transform/W/adam_v	[768, 1536]
decode/decoder/layer_3/encdec_attention/multihead_attention/kv_transform/b	[1536]
decode/decoder/layer_3/encdec_attention/multihead_attention/kv_transform/b/adam_m	[1536]
decode/decoder/layer_3/encdec_attention/multihead_attention/kv_transform/b/adam_v	[1536]
decode/decoder/layer_3/encdec_attention/multihead_attention/output_transform/W	[768, 768]
decode/decoder/layer_3/encdec_attention/multihead_attention/output_transform/W/adam_m	[768, 768]
decode/decoder/layer_3/encdec_attention/multihead_attention/output_transform/W/adam_v	[768, 768]
decode/decoder/layer_3/encdec_attention/multihead_attention/output_transform/b	[768]
decode/decoder/layer_3/encdec_attention/multihead_attention/output_transform/b/adam_m	[768]
decode/decoder/layer_3/encdec_attention/multihead_attention/output_transform/b/adam_v	[768]
decode/decoder/layer_3/encdec_attention/multihead_attention/q_transform/W	[768, 768]
decode/decoder/layer_3/encdec_attention/multihead_attention/q_transform/W/adam_m	[768, 768]
decode/decoder/layer_3/encdec_attention/multihead_attention/q_transform/W/adam_v	[768, 768]
decode/decoder/layer_3/encdec_attention/multihead_attention/q_transform/b	[768]
decode/decoder/layer_3/encdec_attention/multihead_attention/q_transform/b/adam_m	[768]
decode/decoder/layer_3/encdec_attention/multihead_attention/q_transform/b/adam_v	[768]
decode/decoder/layer_3/feed_forward/ffn_layer/input_layer/linear/W	[768, 3072]
decode/decoder/layer_3/feed_forward/ffn_layer/input_layer/linear/W/adam_m	[768, 3072]
decode/decoder/layer_3/feed_forward/ffn_layer/input_layer/linear/W/adam_v	[768, 3072]
decode/decoder/layer_3/feed_forward/ffn_layer/input_layer/linear/b	[3072]
decode/decoder/layer_3/feed_forward/ffn_layer/input_layer/linear/b/adam_m	[3072]
decode/decoder/layer_3/feed_forward/ffn_layer/input_layer/linear/b/adam_v	[3072]
decode/decoder/layer_3/feed_forward/ffn_layer/output_layer/linear/W	[3072, 768]
decode/decoder/layer_3/feed_forward/ffn_layer/output_layer/linear/W/adam_m	[3072, 768]
decode/decoder/layer_3/feed_forward/ffn_layer/output_layer/linear/W/adam_v	[3072, 768]
decode/decoder/layer_3/feed_forward/ffn_layer/output_layer/linear/b	[768]
decode/decoder/layer_3/feed_forward/ffn_layer/output_layer/linear/b/adam_m	[768]
decode/decoder/layer_3/feed_forward/ffn_layer/output_layer/linear/b/adam_v	[768]
decode/decoder/layer_3/feed_forward/layer_norm/bias	[768]
decode/decoder/layer_3/feed_forward/layer_norm/bias/adam_m	[768]
decode/decoder/layer_3/feed_forward/layer_norm/bias/adam_v	[768]
decode/decoder/layer_3/feed_forward/layer_norm/scale	[768]
decode/decoder/layer_3/feed_forward/layer_norm/scale/adam_m	[768]
decode/decoder/layer_3/feed_forward/layer_norm/scale/adam_v	[768]
decode/decoder/layer_3/self_attention/layer_norm/bias	[768]
decode/decoder/layer_3/self_attention/layer_norm/bias/adam_m	[768]
decode/decoder/layer_3/self_attention/layer_norm/bias/adam_v	[768]
decode/decoder/layer_3/self_attention/layer_norm/scale	[768]
decode/decoder/layer_3/self_attention/layer_norm/scale/adam_m	[768]
decode/decoder/layer_3/self_attention/layer_norm/scale/adam_v	[768]
decode/decoder/layer_3/self_attention/multihead_attention/output_transform/W	[768, 768]
decode/decoder/layer_3/self_attention/multihead_attention/output_transform/W/adam_m	[768, 768]
decode/decoder/layer_3/self_attention/multihead_attention/output_transform/W/adam_v	[768, 768]
decode/decoder/layer_3/self_attention/multihead_attention/output_transform/b	[768]
decode/decoder/layer_3/self_attention/multihead_attention/output_transform/b/adam_m	[768]
decode/decoder/layer_3/self_attention/multihead_attention/output_transform/b/adam_v	[768]
decode/decoder/layer_3/self_attention/multihead_attention/qkv_transform/W	[768, 2304]
decode/decoder/layer_3/self_attention/multihead_attention/qkv_transform/W/adam_m	[768, 2304]
decode/decoder/layer_3/self_attention/multihead_attention/qkv_transform/W/adam_v	[768, 2304]
decode/decoder/layer_3/self_attention/multihead_attention/qkv_transform/b	[2304]
decode/decoder/layer_3/self_attention/multihead_attention/qkv_transform/b/adam_m	[2304]
decode/decoder/layer_3/self_attention/multihead_attention/qkv_transform/b/adam_v	[2304]
decode/decoder/layer_4/encdec_attention/layer_norm/bias	[768]
decode/decoder/layer_4/encdec_attention/layer_norm/bias/adam_m	[768]
decode/decoder/layer_4/encdec_attention/layer_norm/bias/adam_v	[768]
decode/decoder/layer_4/encdec_attention/layer_norm/scale	[768]
decode/decoder/layer_4/encdec_attention/layer_norm/scale/adam_m	[768]
decode/decoder/layer_4/encdec_attention/layer_norm/scale/adam_v	[768]
decode/decoder/layer_4/encdec_attention/multihead_attention/kv_transform/W	[768, 1536]
decode/decoder/layer_4/encdec_attention/multihead_attention/kv_transform/W/adam_m	[768, 1536]
decode/decoder/layer_4/encdec_attention/multihead_attention/kv_transform/W/adam_v	[768, 1536]
decode/decoder/layer_4/encdec_attention/multihead_attention/kv_transform/b	[1536]
decode/decoder/layer_4/encdec_attention/multihead_attention/kv_transform/b/adam_m	[1536]
decode/decoder/layer_4/encdec_attention/multihead_attention/kv_transform/b/adam_v	[1536]
decode/decoder/layer_4/encdec_attention/multihead_attention/output_transform/W	[768, 768]
decode/decoder/layer_4/encdec_attention/multihead_attention/output_transform/W/adam_m	[768, 768]
decode/decoder/layer_4/encdec_attention/multihead_attention/output_transform/W/adam_v	[768, 768]
decode/decoder/layer_4/encdec_attention/multihead_attention/output_transform/b	[768]
decode/decoder/layer_4/encdec_attention/multihead_attention/output_transform/b/adam_m	[768]
decode/decoder/layer_4/encdec_attention/multihead_attention/output_transform/b/adam_v	[768]
decode/decoder/layer_4/encdec_attention/multihead_attention/q_transform/W	[768, 768]
decode/decoder/layer_4/encdec_attention/multihead_attention/q_transform/W/adam_m	[768, 768]
decode/decoder/layer_4/encdec_attention/multihead_attention/q_transform/W/adam_v	[768, 768]
decode/decoder/layer_4/encdec_attention/multihead_attention/q_transform/b	[768]
decode/decoder/layer_4/encdec_attention/multihead_attention/q_transform/b/adam_m	[768]
decode/decoder/layer_4/encdec_attention/multihead_attention/q_transform/b/adam_v	[768]
decode/decoder/layer_4/feed_forward/ffn_layer/input_layer/linear/W	[768, 3072]
decode/decoder/layer_4/feed_forward/ffn_layer/input_layer/linear/W/adam_m	[768, 3072]
decode/decoder/layer_4/feed_forward/ffn_layer/input_layer/linear/W/adam_v	[768, 3072]
decode/decoder/layer_4/feed_forward/ffn_layer/input_layer/linear/b	[3072]
decode/decoder/layer_4/feed_forward/ffn_layer/input_layer/linear/b/adam_m	[3072]
decode/decoder/layer_4/feed_forward/ffn_layer/input_layer/linear/b/adam_v	[3072]
decode/decoder/layer_4/feed_forward/ffn_layer/output_layer/linear/W	[3072, 768]
decode/decoder/layer_4/feed_forward/ffn_layer/output_layer/linear/W/adam_m	[3072, 768]
decode/decoder/layer_4/feed_forward/ffn_layer/output_layer/linear/W/adam_v	[3072, 768]
decode/decoder/layer_4/feed_forward/ffn_layer/output_layer/linear/b	[768]
decode/decoder/layer_4/feed_forward/ffn_layer/output_layer/linear/b/adam_m	[768]
decode/decoder/layer_4/feed_forward/ffn_layer/output_layer/linear/b/adam_v	[768]
decode/decoder/layer_4/feed_forward/layer_norm/bias	[768]
decode/decoder/layer_4/feed_forward/layer_norm/bias/adam_m	[768]
decode/decoder/layer_4/feed_forward/layer_norm/bias/adam_v	[768]
decode/decoder/layer_4/feed_forward/layer_norm/scale	[768]
decode/decoder/layer_4/feed_forward/layer_norm/scale/adam_m	[768]
decode/decoder/layer_4/feed_forward/layer_norm/scale/adam_v	[768]
decode/decoder/layer_4/self_attention/layer_norm/bias	[768]
decode/decoder/layer_4/self_attention/layer_norm/bias/adam_m	[768]
decode/decoder/layer_4/self_attention/layer_norm/bias/adam_v	[768]
decode/decoder/layer_4/self_attention/layer_norm/scale	[768]
decode/decoder/layer_4/self_attention/layer_norm/scale/adam_m	[768]
decode/decoder/layer_4/self_attention/layer_norm/scale/adam_v	[768]
decode/decoder/layer_4/self_attention/multihead_attention/output_transform/W	[768, 768]
decode/decoder/layer_4/self_attention/multihead_attention/output_transform/W/adam_m	[768, 768]
decode/decoder/layer_4/self_attention/multihead_attention/output_transform/W/adam_v	[768, 768]
decode/decoder/layer_4/self_attention/multihead_attention/output_transform/b	[768]
decode/decoder/layer_4/self_attention/multihead_attention/output_transform/b/adam_m	[768]
decode/decoder/layer_4/self_attention/multihead_attention/output_transform/b/adam_v	[768]
decode/decoder/layer_4/self_attention/multihead_attention/qkv_transform/W	[768, 2304]
decode/decoder/layer_4/self_attention/multihead_attention/qkv_transform/W/adam_m	[768, 2304]
decode/decoder/layer_4/self_attention/multihead_attention/qkv_transform/W/adam_v	[768, 2304]
decode/decoder/layer_4/self_attention/multihead_attention/qkv_transform/b	[2304]
decode/decoder/layer_4/self_attention/multihead_attention/qkv_transform/b/adam_m	[2304]
decode/decoder/layer_4/self_attention/multihead_attention/qkv_transform/b/adam_v	[2304]
decode/decoder/layer_5/encdec_attention/layer_norm/bias	[768]
decode/decoder/layer_5/encdec_attention/layer_norm/bias/adam_m	[768]
decode/decoder/layer_5/encdec_attention/layer_norm/bias/adam_v	[768]
decode/decoder/layer_5/encdec_attention/layer_norm/scale	[768]
decode/decoder/layer_5/encdec_attention/layer_norm/scale/adam_m	[768]
decode/decoder/layer_5/encdec_attention/layer_norm/scale/adam_v	[768]
decode/decoder/layer_5/encdec_attention/multihead_attention/kv_transform/W	[768, 1536]
decode/decoder/layer_5/encdec_attention/multihead_attention/kv_transform/W/adam_m	[768, 1536]
decode/decoder/layer_5/encdec_attention/multihead_attention/kv_transform/W/adam_v	[768, 1536]
decode/decoder/layer_5/encdec_attention/multihead_attention/kv_transform/b	[1536]
decode/decoder/layer_5/encdec_attention/multihead_attention/kv_transform/b/adam_m	[1536]
decode/decoder/layer_5/encdec_attention/multihead_attention/kv_transform/b/adam_v	[1536]
decode/decoder/layer_5/encdec_attention/multihead_attention/output_transform/W	[768, 768]
decode/decoder/layer_5/encdec_attention/multihead_attention/output_transform/W/adam_m	[768, 768]
decode/decoder/layer_5/encdec_attention/multihead_attention/output_transform/W/adam_v	[768, 768]
decode/decoder/layer_5/encdec_attention/multihead_attention/output_transform/b	[768]
decode/decoder/layer_5/encdec_attention/multihead_attention/output_transform/b/adam_m	[768]
decode/decoder/layer_5/encdec_attention/multihead_attention/output_transform/b/adam_v	[768]
decode/decoder/layer_5/encdec_attention/multihead_attention/q_transform/W	[768, 768]
decode/decoder/layer_5/encdec_attention/multihead_attention/q_transform/W/adam_m	[768, 768]
decode/decoder/layer_5/encdec_attention/multihead_attention/q_transform/W/adam_v	[768, 768]
decode/decoder/layer_5/encdec_attention/multihead_attention/q_transform/b	[768]
decode/decoder/layer_5/encdec_attention/multihead_attention/q_transform/b/adam_m	[768]
decode/decoder/layer_5/encdec_attention/multihead_attention/q_transform/b/adam_v	[768]
decode/decoder/layer_5/feed_forward/ffn_layer/input_layer/linear/W	[768, 3072]
decode/decoder/layer_5/feed_forward/ffn_layer/input_layer/linear/W/adam_m	[768, 3072]
decode/decoder/layer_5/feed_forward/ffn_layer/input_layer/linear/W/adam_v	[768, 3072]
decode/decoder/layer_5/feed_forward/ffn_layer/input_layer/linear/b	[3072]
decode/decoder/layer_5/feed_forward/ffn_layer/input_layer/linear/b/adam_m	[3072]
decode/decoder/layer_5/feed_forward/ffn_layer/input_layer/linear/b/adam_v	[3072]
decode/decoder/layer_5/feed_forward/ffn_layer/output_layer/linear/W	[3072, 768]
decode/decoder/layer_5/feed_forward/ffn_layer/output_layer/linear/W/adam_m	[3072, 768]
decode/decoder/layer_5/feed_forward/ffn_layer/output_layer/linear/W/adam_v	[3072, 768]
decode/decoder/layer_5/feed_forward/ffn_layer/output_layer/linear/b	[768]
decode/decoder/layer_5/feed_forward/ffn_layer/output_layer/linear/b/adam_m	[768]
decode/decoder/layer_5/feed_forward/ffn_layer/output_layer/linear/b/adam_v	[768]
decode/decoder/layer_5/feed_forward/layer_norm/bias	[768]
decode/decoder/layer_5/feed_forward/layer_norm/bias/adam_m	[768]
decode/decoder/layer_5/feed_forward/layer_norm/bias/adam_v	[768]
decode/decoder/layer_5/feed_forward/layer_norm/scale	[768]
decode/decoder/layer_5/feed_forward/layer_norm/scale/adam_m	[768]
decode/decoder/layer_5/feed_forward/layer_norm/scale/adam_v	[768]
decode/decoder/layer_5/self_attention/layer_norm/bias	[768]
decode/decoder/layer_5/self_attention/layer_norm/bias/adam_m	[768]
decode/decoder/layer_5/self_attention/layer_norm/bias/adam_v	[768]
decode/decoder/layer_5/self_attention/layer_norm/scale	[768]
decode/decoder/layer_5/self_attention/layer_norm/scale/adam_m	[768]
decode/decoder/layer_5/self_attention/layer_norm/scale/adam_v	[768]
decode/decoder/layer_5/self_attention/multihead_attention/output_transform/W	[768, 768]
decode/decoder/layer_5/self_attention/multihead_attention/output_transform/W/adam_m	[768, 768]
decode/decoder/layer_5/self_attention/multihead_attention/output_transform/W/adam_v	[768, 768]
decode/decoder/layer_5/self_attention/multihead_attention/output_transform/b	[768]
decode/decoder/layer_5/self_attention/multihead_attention/output_transform/b/adam_m	[768]
decode/decoder/layer_5/self_attention/multihead_attention/output_transform/b/adam_v	[768]
decode/decoder/layer_5/self_attention/multihead_attention/qkv_transform/W	[768, 2304]
decode/decoder/layer_5/self_attention/multihead_attention/qkv_transform/W/adam_m	[768, 2304]
decode/decoder/layer_5/self_attention/multihead_attention/qkv_transform/W/adam_v	[768, 2304]
decode/decoder/layer_5/self_attention/multihead_attention/qkv_transform/b	[2304]
decode/decoder/layer_5/self_attention/multihead_attention/qkv_transform/b/adam_m	[2304]
decode/decoder/layer_5/self_attention/multihead_attention/qkv_transform/b/adam_v	[2304]
decode/decoder/layer_6/encdec_attention/layer_norm/bias	[768]
decode/decoder/layer_6/encdec_attention/layer_norm/bias/adam_m	[768]
decode/decoder/layer_6/encdec_attention/layer_norm/bias/adam_v	[768]
decode/decoder/layer_6/encdec_attention/layer_norm/scale	[768]
decode/decoder/layer_6/encdec_attention/layer_norm/scale/adam_m	[768]
decode/decoder/layer_6/encdec_attention/layer_norm/scale/adam_v	[768]
decode/decoder/layer_6/encdec_attention/multihead_attention/kv_transform/W	[768, 1536]
decode/decoder/layer_6/encdec_attention/multihead_attention/kv_transform/W/adam_m	[768, 1536]
decode/decoder/layer_6/encdec_attention/multihead_attention/kv_transform/W/adam_v	[768, 1536]
decode/decoder/layer_6/encdec_attention/multihead_attention/kv_transform/b	[1536]
decode/decoder/layer_6/encdec_attention/multihead_attention/kv_transform/b/adam_m	[1536]
decode/decoder/layer_6/encdec_attention/multihead_attention/kv_transform/b/adam_v	[1536]
decode/decoder/layer_6/encdec_attention/multihead_attention/output_transform/W	[768, 768]
decode/decoder/layer_6/encdec_attention/multihead_attention/output_transform/W/adam_m	[768, 768]
decode/decoder/layer_6/encdec_attention/multihead_attention/output_transform/W/adam_v	[768, 768]
decode/decoder/layer_6/encdec_attention/multihead_attention/output_transform/b	[768]
decode/decoder/layer_6/encdec_attention/multihead_attention/output_transform/b/adam_m	[768]
decode/decoder/layer_6/encdec_attention/multihead_attention/output_transform/b/adam_v	[768]
decode/decoder/layer_6/encdec_attention/multihead_attention/q_transform/W	[768, 768]
decode/decoder/layer_6/encdec_attention/multihead_attention/q_transform/W/adam_m	[768, 768]
decode/decoder/layer_6/encdec_attention/multihead_attention/q_transform/W/adam_v	[768, 768]
decode/decoder/layer_6/encdec_attention/multihead_attention/q_transform/b	[768]
decode/decoder/layer_6/encdec_attention/multihead_attention/q_transform/b/adam_m	[768]
decode/decoder/layer_6/encdec_attention/multihead_attention/q_transform/b/adam_v	[768]
decode/decoder/layer_6/feed_forward/ffn_layer/input_layer/linear/W	[768, 3072]
decode/decoder/layer_6/feed_forward/ffn_layer/input_layer/linear/W/adam_m	[768, 3072]
decode/decoder/layer_6/feed_forward/ffn_layer/input_layer/linear/W/adam_v	[768, 3072]
decode/decoder/layer_6/feed_forward/ffn_layer/input_layer/linear/b	[3072]
decode/decoder/layer_6/feed_forward/ffn_layer/input_layer/linear/b/adam_m	[3072]
decode/decoder/layer_6/feed_forward/ffn_layer/input_layer/linear/b/adam_v	[3072]
decode/decoder/layer_6/feed_forward/ffn_layer/output_layer/linear/W	[3072, 768]
decode/decoder/layer_6/feed_forward/ffn_layer/output_layer/linear/W/adam_m	[3072, 768]
decode/decoder/layer_6/feed_forward/ffn_layer/output_layer/linear/W/adam_v	[3072, 768]
decode/decoder/layer_6/feed_forward/ffn_layer/output_layer/linear/b	[768]
decode/decoder/layer_6/feed_forward/ffn_layer/output_layer/linear/b/adam_m	[768]
decode/decoder/layer_6/feed_forward/ffn_layer/output_layer/linear/b/adam_v	[768]
decode/decoder/layer_6/feed_forward/layer_norm/bias	[768]
decode/decoder/layer_6/feed_forward/layer_norm/bias/adam_m	[768]
decode/decoder/layer_6/feed_forward/layer_norm/bias/adam_v	[768]
decode/decoder/layer_6/feed_forward/layer_norm/scale	[768]
decode/decoder/layer_6/feed_forward/layer_norm/scale/adam_m	[768]
decode/decoder/layer_6/feed_forward/layer_norm/scale/adam_v	[768]
decode/decoder/layer_6/self_attention/layer_norm/bias	[768]
decode/decoder/layer_6/self_attention/layer_norm/bias/adam_m	[768]
decode/decoder/layer_6/self_attention/layer_norm/bias/adam_v	[768]
decode/decoder/layer_6/self_attention/layer_norm/scale	[768]
decode/decoder/layer_6/self_attention/layer_norm/scale/adam_m	[768]
decode/decoder/layer_6/self_attention/layer_norm/scale/adam_v	[768]
decode/decoder/layer_6/self_attention/multihead_attention/output_transform/W	[768, 768]
decode/decoder/layer_6/self_attention/multihead_attention/output_transform/W/adam_m	[768, 768]
decode/decoder/layer_6/self_attention/multihead_attention/output_transform/W/adam_v	[768, 768]
decode/decoder/layer_6/self_attention/multihead_attention/output_transform/b	[768]
decode/decoder/layer_6/self_attention/multihead_attention/output_transform/b/adam_m	[768]
decode/decoder/layer_6/self_attention/multihead_attention/output_transform/b/adam_v	[768]
decode/decoder/layer_6/self_attention/multihead_attention/qkv_transform/W	[768, 2304]
decode/decoder/layer_6/self_attention/multihead_attention/qkv_transform/W/adam_m	[768, 2304]
decode/decoder/layer_6/self_attention/multihead_attention/qkv_transform/W/adam_v	[768, 2304]
decode/decoder/layer_6/self_attention/multihead_attention/qkv_transform/b	[2304]
decode/decoder/layer_6/self_attention/multihead_attention/qkv_transform/b/adam_m	[2304]
decode/decoder/layer_6/self_attention/multihead_attention/qkv_transform/b/adam_v	[2304]
decode/decoder/layer_7/encdec_attention/layer_norm/bias	[768]
decode/decoder/layer_7/encdec_attention/layer_norm/bias/adam_m	[768]
decode/decoder/layer_7/encdec_attention/layer_norm/bias/adam_v	[768]
decode/decoder/layer_7/encdec_attention/layer_norm/scale	[768]
decode/decoder/layer_7/encdec_attention/layer_norm/scale/adam_m	[768]
decode/decoder/layer_7/encdec_attention/layer_norm/scale/adam_v	[768]
decode/decoder/layer_7/encdec_attention/multihead_attention/kv_transform/W	[768, 1536]
decode/decoder/layer_7/encdec_attention/multihead_attention/kv_transform/W/adam_m	[768, 1536]
decode/decoder/layer_7/encdec_attention/multihead_attention/kv_transform/W/adam_v	[768, 1536]
decode/decoder/layer_7/encdec_attention/multihead_attention/kv_transform/b	[1536]
decode/decoder/layer_7/encdec_attention/multihead_attention/kv_transform/b/adam_m	[1536]
decode/decoder/layer_7/encdec_attention/multihead_attention/kv_transform/b/adam_v	[1536]
decode/decoder/layer_7/encdec_attention/multihead_attention/output_transform/W	[768, 768]
decode/decoder/layer_7/encdec_attention/multihead_attention/output_transform/W/adam_m	[768, 768]
decode/decoder/layer_7/encdec_attention/multihead_attention/output_transform/W/adam_v	[768, 768]
decode/decoder/layer_7/encdec_attention/multihead_attention/output_transform/b	[768]
decode/decoder/layer_7/encdec_attention/multihead_attention/output_transform/b/adam_m	[768]
decode/decoder/layer_7/encdec_attention/multihead_attention/output_transform/b/adam_v	[768]
decode/decoder/layer_7/encdec_attention/multihead_attention/q_transform/W	[768, 768]
decode/decoder/layer_7/encdec_attention/multihead_attention/q_transform/W/adam_m	[768, 768]
decode/decoder/layer_7/encdec_attention/multihead_attention/q_transform/W/adam_v	[768, 768]
decode/decoder/layer_7/encdec_attention/multihead_attention/q_transform/b	[768]
decode/decoder/layer_7/encdec_attention/multihead_attention/q_transform/b/adam_m	[768]
decode/decoder/layer_7/encdec_attention/multihead_attention/q_transform/b/adam_v	[768]
decode/decoder/layer_7/feed_forward/ffn_layer/input_layer/linear/W	[768, 3072]
decode/decoder/layer_7/feed_forward/ffn_layer/input_layer/linear/W/adam_m	[768, 3072]
decode/decoder/layer_7/feed_forward/ffn_layer/input_layer/linear/W/adam_v	[768, 3072]
decode/decoder/layer_7/feed_forward/ffn_layer/input_layer/linear/b	[3072]
decode/decoder/layer_7/feed_forward/ffn_layer/input_layer/linear/b/adam_m	[3072]
decode/decoder/layer_7/feed_forward/ffn_layer/input_layer/linear/b/adam_v	[3072]
decode/decoder/layer_7/feed_forward/ffn_layer/output_layer/linear/W	[3072, 768]
decode/decoder/layer_7/feed_forward/ffn_layer/output_layer/linear/W/adam_m	[3072, 768]
decode/decoder/layer_7/feed_forward/ffn_layer/output_layer/linear/W/adam_v	[3072, 768]
decode/decoder/layer_7/feed_forward/ffn_layer/output_layer/linear/b	[768]
decode/decoder/layer_7/feed_forward/ffn_layer/output_layer/linear/b/adam_m	[768]
decode/decoder/layer_7/feed_forward/ffn_layer/output_layer/linear/b/adam_v	[768]
decode/decoder/layer_7/feed_forward/layer_norm/bias	[768]
decode/decoder/layer_7/feed_forward/layer_norm/bias/adam_m	[768]
decode/decoder/layer_7/feed_forward/layer_norm/bias/adam_v	[768]
decode/decoder/layer_7/feed_forward/layer_norm/scale	[768]
decode/decoder/layer_7/feed_forward/layer_norm/scale/adam_m	[768]
decode/decoder/layer_7/feed_forward/layer_norm/scale/adam_v	[768]
decode/decoder/layer_7/self_attention/layer_norm/bias	[768]
decode/decoder/layer_7/self_attention/layer_norm/bias/adam_m	[768]
decode/decoder/layer_7/self_attention/layer_norm/bias/adam_v	[768]
decode/decoder/layer_7/self_attention/layer_norm/scale	[768]
decode/decoder/layer_7/self_attention/layer_norm/scale/adam_m	[768]
decode/decoder/layer_7/self_attention/layer_norm/scale/adam_v	[768]
decode/decoder/layer_7/self_attention/multihead_attention/output_transform/W	[768, 768]
decode/decoder/layer_7/self_attention/multihead_attention/output_transform/W/adam_m	[768, 768]
decode/decoder/layer_7/self_attention/multihead_attention/output_transform/W/adam_v	[768, 768]
decode/decoder/layer_7/self_attention/multihead_attention/output_transform/b	[768]
decode/decoder/layer_7/self_attention/multihead_attention/output_transform/b/adam_m	[768]
decode/decoder/layer_7/self_attention/multihead_attention/output_transform/b/adam_v	[768]
decode/decoder/layer_7/self_attention/multihead_attention/qkv_transform/W	[768, 2304]
decode/decoder/layer_7/self_attention/multihead_attention/qkv_transform/W/adam_m	[768, 2304]
decode/decoder/layer_7/self_attention/multihead_attention/qkv_transform/W/adam_v	[768, 2304]
decode/decoder/layer_7/self_attention/multihead_attention/qkv_transform/b	[2304]
decode/decoder/layer_7/self_attention/multihead_attention/qkv_transform/b/adam_m	[2304]
decode/decoder/layer_7/self_attention/multihead_attention/qkv_transform/b/adam_v	[2304]
decode/decoder/layer_8/encdec_attention/layer_norm/bias	[768]
decode/decoder/layer_8/encdec_attention/layer_norm/bias/adam_m	[768]
decode/decoder/layer_8/encdec_attention/layer_norm/bias/adam_v	[768]
decode/decoder/layer_8/encdec_attention/layer_norm/scale	[768]
decode/decoder/layer_8/encdec_attention/layer_norm/scale/adam_m	[768]
decode/decoder/layer_8/encdec_attention/layer_norm/scale/adam_v	[768]
decode/decoder/layer_8/encdec_attention/multihead_attention/kv_transform/W	[768, 1536]
decode/decoder/layer_8/encdec_attention/multihead_attention/kv_transform/W/adam_m	[768, 1536]
decode/decoder/layer_8/encdec_attention/multihead_attention/kv_transform/W/adam_v	[768, 1536]
decode/decoder/layer_8/encdec_attention/multihead_attention/kv_transform/b	[1536]
decode/decoder/layer_8/encdec_attention/multihead_attention/kv_transform/b/adam_m	[1536]
decode/decoder/layer_8/encdec_attention/multihead_attention/kv_transform/b/adam_v	[1536]
decode/decoder/layer_8/encdec_attention/multihead_attention/output_transform/W	[768, 768]
decode/decoder/layer_8/encdec_attention/multihead_attention/output_transform/W/adam_m	[768, 768]
decode/decoder/layer_8/encdec_attention/multihead_attention/output_transform/W/adam_v	[768, 768]
decode/decoder/layer_8/encdec_attention/multihead_attention/output_transform/b	[768]
decode/decoder/layer_8/encdec_attention/multihead_attention/output_transform/b/adam_m	[768]
decode/decoder/layer_8/encdec_attention/multihead_attention/output_transform/b/adam_v	[768]
decode/decoder/layer_8/encdec_attention/multihead_attention/q_transform/W	[768, 768]
decode/decoder/layer_8/encdec_attention/multihead_attention/q_transform/W/adam_m	[768, 768]
decode/decoder/layer_8/encdec_attention/multihead_attention/q_transform/W/adam_v	[768, 768]
decode/decoder/layer_8/encdec_attention/multihead_attention/q_transform/b	[768]
decode/decoder/layer_8/encdec_attention/multihead_attention/q_transform/b/adam_m	[768]
decode/decoder/layer_8/encdec_attention/multihead_attention/q_transform/b/adam_v	[768]
decode/decoder/layer_8/feed_forward/ffn_layer/input_layer/linear/W	[768, 3072]
decode/decoder/layer_8/feed_forward/ffn_layer/input_layer/linear/W/adam_m	[768, 3072]
decode/decoder/layer_8/feed_forward/ffn_layer/input_layer/linear/W/adam_v	[768, 3072]
decode/decoder/layer_8/feed_forward/ffn_layer/input_layer/linear/b	[3072]
decode/decoder/layer_8/feed_forward/ffn_layer/input_layer/linear/b/adam_m	[3072]
decode/decoder/layer_8/feed_forward/ffn_layer/input_layer/linear/b/adam_v	[3072]
decode/decoder/layer_8/feed_forward/ffn_layer/output_layer/linear/W	[3072, 768]
decode/decoder/layer_8/feed_forward/ffn_layer/output_layer/linear/W/adam_m	[3072, 768]
decode/decoder/layer_8/feed_forward/ffn_layer/output_layer/linear/W/adam_v	[3072, 768]
decode/decoder/layer_8/feed_forward/ffn_layer/output_layer/linear/b	[768]
decode/decoder/layer_8/feed_forward/ffn_layer/output_layer/linear/b/adam_m	[768]
decode/decoder/layer_8/feed_forward/ffn_layer/output_layer/linear/b/adam_v	[768]
decode/decoder/layer_8/feed_forward/layer_norm/bias	[768]
decode/decoder/layer_8/feed_forward/layer_norm/bias/adam_m	[768]
decode/decoder/layer_8/feed_forward/layer_norm/bias/adam_v	[768]
decode/decoder/layer_8/feed_forward/layer_norm/scale	[768]
decode/decoder/layer_8/feed_forward/layer_norm/scale/adam_m	[768]
decode/decoder/layer_8/feed_forward/layer_norm/scale/adam_v	[768]
decode/decoder/layer_8/self_attention/layer_norm/bias	[768]
decode/decoder/layer_8/self_attention/layer_norm/bias/adam_m	[768]
decode/decoder/layer_8/self_attention/layer_norm/bias/adam_v	[768]
decode/decoder/layer_8/self_attention/layer_norm/scale	[768]
decode/decoder/layer_8/self_attention/layer_norm/scale/adam_m	[768]
decode/decoder/layer_8/self_attention/layer_norm/scale/adam_v	[768]
decode/decoder/layer_8/self_attention/multihead_attention/output_transform/W	[768, 768]
decode/decoder/layer_8/self_attention/multihead_attention/output_transform/W/adam_m	[768, 768]
decode/decoder/layer_8/self_attention/multihead_attention/output_transform/W/adam_v	[768, 768]
decode/decoder/layer_8/self_attention/multihead_attention/output_transform/b	[768]
decode/decoder/layer_8/self_attention/multihead_attention/output_transform/b/adam_m	[768]
decode/decoder/layer_8/self_attention/multihead_attention/output_transform/b/adam_v	[768]
decode/decoder/layer_8/self_attention/multihead_attention/qkv_transform/W	[768, 2304]
decode/decoder/layer_8/self_attention/multihead_attention/qkv_transform/W/adam_m	[768, 2304]
decode/decoder/layer_8/self_attention/multihead_attention/qkv_transform/W/adam_v	[768, 2304]
decode/decoder/layer_8/self_attention/multihead_attention/qkv_transform/b	[2304]
decode/decoder/layer_8/self_attention/multihead_attention/qkv_transform/b/adam_m	[2304]
decode/decoder/layer_8/self_attention/multihead_attention/qkv_transform/b/adam_v	[2304]
decode/decoder/layer_9/encdec_attention/layer_norm/bias	[768]
decode/decoder/layer_9/encdec_attention/layer_norm/bias/adam_m	[768]
decode/decoder/layer_9/encdec_attention/layer_norm/bias/adam_v	[768]
decode/decoder/layer_9/encdec_attention/layer_norm/scale	[768]
decode/decoder/layer_9/encdec_attention/layer_norm/scale/adam_m	[768]
decode/decoder/layer_9/encdec_attention/layer_norm/scale/adam_v	[768]
decode/decoder/layer_9/encdec_attention/multihead_attention/kv_transform/W	[768, 1536]
decode/decoder/layer_9/encdec_attention/multihead_attention/kv_transform/W/adam_m	[768, 1536]
decode/decoder/layer_9/encdec_attention/multihead_attention/kv_transform/W/adam_v	[768, 1536]
decode/decoder/layer_9/encdec_attention/multihead_attention/kv_transform/b	[1536]
decode/decoder/layer_9/encdec_attention/multihead_attention/kv_transform/b/adam_m	[1536]
decode/decoder/layer_9/encdec_attention/multihead_attention/kv_transform/b/adam_v	[1536]
decode/decoder/layer_9/encdec_attention/multihead_attention/output_transform/W	[768, 768]
decode/decoder/layer_9/encdec_attention/multihead_attention/output_transform/W/adam_m	[768, 768]
decode/decoder/layer_9/encdec_attention/multihead_attention/output_transform/W/adam_v	[768, 768]
decode/decoder/layer_9/encdec_attention/multihead_attention/output_transform/b	[768]
decode/decoder/layer_9/encdec_attention/multihead_attention/output_transform/b/adam_m	[768]
decode/decoder/layer_9/encdec_attention/multihead_attention/output_transform/b/adam_v	[768]
decode/decoder/layer_9/encdec_attention/multihead_attention/q_transform/W	[768, 768]
decode/decoder/layer_9/encdec_attention/multihead_attention/q_transform/W/adam_m	[768, 768]
decode/decoder/layer_9/encdec_attention/multihead_attention/q_transform/W/adam_v	[768, 768]
decode/decoder/layer_9/encdec_attention/multihead_attention/q_transform/b	[768]
decode/decoder/layer_9/encdec_attention/multihead_attention/q_transform/b/adam_m	[768]
decode/decoder/layer_9/encdec_attention/multihead_attention/q_transform/b/adam_v	[768]
decode/decoder/layer_9/feed_forward/ffn_layer/input_layer/linear/W	[768, 3072]
decode/decoder/layer_9/feed_forward/ffn_layer/input_layer/linear/W/adam_m	[768, 3072]
decode/decoder/layer_9/feed_forward/ffn_layer/input_layer/linear/W/adam_v	[768, 3072]
decode/decoder/layer_9/feed_forward/ffn_layer/input_layer/linear/b	[3072]
decode/decoder/layer_9/feed_forward/ffn_layer/input_layer/linear/b/adam_m	[3072]
decode/decoder/layer_9/feed_forward/ffn_layer/input_layer/linear/b/adam_v	[3072]
decode/decoder/layer_9/feed_forward/ffn_layer/output_layer/linear/W	[3072, 768]
decode/decoder/layer_9/feed_forward/ffn_layer/output_layer/linear/W/adam_m	[3072, 768]
decode/decoder/layer_9/feed_forward/ffn_layer/output_layer/linear/W/adam_v	[3072, 768]
decode/decoder/layer_9/feed_forward/ffn_layer/output_layer/linear/b	[768]
decode/decoder/layer_9/feed_forward/ffn_layer/output_layer/linear/b/adam_m	[768]
decode/decoder/layer_9/feed_forward/ffn_layer/output_layer/linear/b/adam_v	[768]
decode/decoder/layer_9/feed_forward/layer_norm/bias	[768]
decode/decoder/layer_9/feed_forward/layer_norm/bias/adam_m	[768]
decode/decoder/layer_9/feed_forward/layer_norm/bias/adam_v	[768]
decode/decoder/layer_9/feed_forward/layer_norm/scale	[768]
decode/decoder/layer_9/feed_forward/layer_norm/scale/adam_m	[768]
decode/decoder/layer_9/feed_forward/layer_norm/scale/adam_v	[768]
decode/decoder/layer_9/self_attention/layer_norm/bias	[768]
decode/decoder/layer_9/self_attention/layer_norm/bias/adam_m	[768]
decode/decoder/layer_9/self_attention/layer_norm/bias/adam_v	[768]
decode/decoder/layer_9/self_attention/layer_norm/scale	[768]
decode/decoder/layer_9/self_attention/layer_norm/scale/adam_m	[768]
decode/decoder/layer_9/self_attention/layer_norm/scale/adam_v	[768]
decode/decoder/layer_9/self_attention/multihead_attention/output_transform/W	[768, 768]
decode/decoder/layer_9/self_attention/multihead_attention/output_transform/W/adam_m	[768, 768]
decode/decoder/layer_9/self_attention/multihead_attention/output_transform/W/adam_v	[768, 768]
decode/decoder/layer_9/self_attention/multihead_attention/output_transform/b	[768]
decode/decoder/layer_9/self_attention/multihead_attention/output_transform/b/adam_m	[768]
decode/decoder/layer_9/self_attention/multihead_attention/output_transform/b/adam_v	[768]
decode/decoder/layer_9/self_attention/multihead_attention/qkv_transform/W	[768, 2304]
decode/decoder/layer_9/self_attention/multihead_attention/qkv_transform/W/adam_m	[768, 2304]
decode/decoder/layer_9/self_attention/multihead_attention/qkv_transform/W/adam_v	[768, 2304]
decode/decoder/layer_9/self_attention/multihead_attention/qkv_transform/b	[2304]
decode/decoder/layer_9/self_attention/multihead_attention/qkv_transform/b/adam_m	[2304]
decode/decoder/layer_9/self_attention/multihead_attention/qkv_transform/b/adam_v	[2304]
decode/decoder/layer_norm/bias	[768]
decode/decoder/layer_norm/bias/adam_m	[768]
decode/decoder/layer_norm/bias/adam_v	[768]
decode/decoder/layer_norm/scale	[768]
decode/decoder/layer_norm/scale/adam_m	[768]
decode/decoder/layer_norm/scale/adam_v	[768]
global_step	[]




